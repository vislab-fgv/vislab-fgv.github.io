[
  {
    "id": 0,
    "title": "Piecewise Laplacian-based Projection for Interactive Large Data Exploration and Organization",
    "venue_id": 17,
    "venue": "CGF",
    "web_name": "PLP",
    "year": 2011,
    "bibtext": "2011-PLP",
    "pdf": "files/papers/2011-PLP-CGF.pdf",
    "thumbnail": "images/thumbs/2011-PLP.png",
    "figure": "images/figures/2011-PLP.png",
    "caption": "",
    "start_page": 1091,
    "end_page": 1100,
    "volume": 30,
    "issue": 3,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Multidimensional projection is emerging as an important visualization tool in applications involving the visual analysis of high-dimensional data. However, existing projection methods are either computationally expensive or not flexible enough to enable fully interactive data manipulation. That is, they do not support the feedback of user interaction into the projection process. A mechanism that dynamically adapts the projection based on direct user interaction would go a long way towards making the technique more useful with a large range of applications and data sets. In this paper we propose the Piecewise Laplacian-based Projection (PLP), a novel multidimensional projection technique, that, due to the local nature of its formulation, enables a versatile mechanism to interact with projected data and to allow interactive changes to dynamically alter the projection map, a unique capability of the technique. We exploit the flexibility provided by PLP in two interactive projection-based applications, one designed to organize pictures visually and another to build music playlists. These applications illustrate the usefulness of PLP in handling high-dimensional data in a flexible and highly visual way. We also compare PLP with the currently most promising projections in terms of precision and speed. The results show that PLP perform very well also according to these quality criteria.",
    "note": "",
    "pub_date": "2011-06-28",
    "url": "https://doi.org/10.1111/j.1467-8659.2011.01958.x",
    "authors": [26, 27, 0, 28, 29, 18]
  },
  {
    "id": 1,
    "title": "A Framework for Exploring Multidimensional Data with 3D Projections",
    "venue_id": 17,
    "venue": "CGF",
    "web_name": "3DProjections",
    "year": 2011,
    "bibtext": "2011-3DProjections",
    "pdf": "files/papers/2011-3DProjections-CGF.pdf",
    "thumbnail": "images/thumbs/2011-3DProjections.png",
    "figure": "images/figures/2011-3DProjections.png",
    "caption": "",
    "start_page": 1111,
    "end_page": 1120,
    "volume": 30,
    "issue": 3,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Visualization of high-dimensional data requires a mapping to a visual space. Whenever the goal is to preserve similarity relations a frequent strategy is to use 2D projections, which afford intuitive interactive exploration, e.g., by users locating and selecting groups and gradually drilling down to individual objects. In this paper, we propose a framework for projecting high-dimensional data to 3D visual spaces, based on a generalization of the Least-Square Projection (LSP). We compare projections to 2D and 3D visual spaces both quantitatively and through a user study considering certain exploration tasks. The quantitative analysis confirms that 3D projections outperform 2D projections in terms of precision. The user study indicates that certain tasks can be more reliably and confidently answered with 3D projections. Nonetheless, as 3D projections are displayed on 2D screens, interaction is more difficult. Therefore, we incorporate suitable interaction functionalities into our framework that supports 3D transformations, predefined optimal 2D views, coordinated 2D and 3D views, and hierarchical 3D cluster definition and exploration. For visually encoding data clusters in a 3D setup, we employ color coding of projected data points as well as four types of surface renderings. A second user study evaluates the suitability of these visual encodings. Several examples illustrate the framework’s applicability to visual exploration of multidimensional abstract (non-spatial) data as well as the feature space of multi-variate spatial data.",
    "note": "",
    "pub_date": "2011-06-28",
    "url": "https://doi.org/10.1111/j.1467-8659.2011.01960.x",
    "authors": [0, 30, 26, 31, 32, 33, 34],
    "links": [
      {
        "name": "Presentation",
        "file": "files/slides/2011-3DProjections-CGF.pdf"
      }
    ]
  },
  {
    "id": 2,
    "title": "Employing 2D projections for fast visual exploration of large fiber tracking data",
    "venue_id": 17,
    "venue": "CGF",
    "web_name": "FibersProjection",
    "year": 2012,
    "bibtext": "2012-FibersProjection",
    "pdf": "files/papers/2012-FibersProjection-CGF.pdf",
    "thumbnail": "images/thumbs/2012-FibersProjection.png",
    "figure": "images/figures/2012-FibersProjection.png",
    "caption": "",
    "start_page": 1075,
    "end_page": 1084,
    "volume": 31,
    "issue": 3,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Fiber tracts detection is an increasingly common technology for diagnosis and also understanding of brain function. Although tools for tracing and presenting brain fibers are advanced, it is still difficult for physicians or students to explore the dataset in 3D due to their intricate topology. In this work we present a visual exploration approach for fiber tracts data aimed at supporting exploration of such data. The work employs a local, precise and fast 2D multidimensional projection technique that allows a large number of fibers to be handled simultaneously and to select groups of bundled fibers for further exploration. In this approach, a DTI feature dataset, including curvature as well as spatial features, is projected on a 2D or 3D view. By handling groups formed in this view, exploration is linked to corresponding brain fibers in object space. The link exists in both directions and fibers selected in object space are also mapped to feature space. Our approach also allows users to modify the projection, controlling and improving, if necessary, the definition of groups of fibers for small and large datasets, due to the local nature of the projection. Compared to other related work, the method presented here is faster for creating visual representations, making it possible to explore complete sets of fibers tracts up to 250K fibers, which was not possible previously. Additionally, the ability to change configuration of the feature space representation adds a high degree of flexibility to the process.",
    "note": "",
    "pub_date": "2012-05-25",
    "url": "http://dx.doi.org/10.1111/j.1467-8659.2012.03100.x",
    "authors": [0, 27, 26, 29],
    "links": [
      {
        "name": "Presentation",
        "file": "files/slides/2012-FibersProjection-CGF.pdf"
      }
    ]
  },
  {
    "id": 3,
    "title": "UV-CDAT: Analyzing climate datasets from a user’s perspective",
    "venue_id": 14,
    "venue": "CiSE",
    "web_name": "UVCDAT-User",
    "year": 2013,
    "bibtext": "2013-UVCDAT-User",
    "pdf": "files/papers/2013-UVCDAT-User-CiSE.pdf",
    "thumbnail": "images/thumbs/2013-UVCDAT-User.png",
    "figure": "images/figures/2013-UVCDAT-User.png",
    "caption": "",
    "start_page": 94,
    "end_page": 103,
    "volume": 15,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "The Ultra-scale Visualization Climate Data Analysis Tools (UV-CDAT) is a new tool for analyzing and visualizing climate data. Here we provide some pointers, background information, and examples to show how the system works.",
    "note": "",
    "pub_date": "2013-01-21",
    "url": "https://doi.org/10.1109/MCSE.2013.15",
    "authors": [35, 0, 36, 37, 38, 39, 15],
    "links": [
      {
        "name": "Website",
        "link": "http://uv-cdat.llnl.gov/"
      },
      {
        "name": "Data",
        "link": "http://bigdata.poly.edu/projects/uvcdat/cise2012data/"
      }
    ]
  },
  {
    "id": 4,
    "title": "Ultrascale Visualization of Climate Data",
    "venue_id": 12,
    "venue": "Computer",
    "web_name": "UVCDAT",
    "year": 2013,
    "bibtext": "2013-UVCDAT",
    "pdf": "files/papers/2013-UVCDAT-Computer.pdf",
    "thumbnail": "images/thumbs/2013-UVCDAT.png",
    "figure": "images/figures/2013-UVCDAT.png",
    "caption": "",
    "start_page": 68,
    "end_page": 76,
    "volume": 46,
    "issue": 9,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Collaboration across research, government, academic, and private sectors is integrating more than 70 scientific computing libraries and applications through a tailorable provenance framework, empowering scientists to exchange and examine data in novel ways.",
    "note": "",
    "pub_date": "2013-09-30",
    "url": "https://doi.ieeecomputersociety.org/10.1109/MC.2013.119",
    "authors": [
      39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 15, 35, 54,
      55, 0, 56, 57, 58, 59, 60, 61, 62
    ]
  },
  {
    "id": 5,
    "title": "Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Cab Trips",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "TaxiVis",
    "year": 2013,
    "bibtext": "2013-TaxiVis",
    "pdf": "files/papers/2013-TaxiVis-TVCG.pdf",
    "thumbnail": "images/thumbs/2013-TaxiVis.png",
    "figure": "images/figures/2013-TaxiVis.png",
    "caption": "Comparison  of  taxi  trips  from  Lower  Manhattan  to  JFK  and  LGA  airports  in  May  2011.   The  query  on  the  left  selectstrips that occurred on Sundays, while the one on the right selects trips that occurred on Mondays.  Users specify these queries byvisually selecting regions on the map and connecting them.  In addition to inspecting the results depicted on the map, i.e., the dotscorresponding to pickups (blue) and dropoffs (orange) of the selected trips, they can also explore the results through other visualrepresentations. The scatter plots below the maps show the relationship between hour of the day and trip duration. Points in the plotsare colored according to the spatial constraint represented by the arrows between the regions: trips to JFK in blue, and trips to LGAin red. The plots show that many of the trips on Monday between 3PM and 5PM take much longer than trips on Sundays.",
    "start_page": 2149,
    "end_page": 2158,
    "volume": 19,
    "issue": 12,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data - there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.",
    "note": "",
    "pub_date": "2013-10-16",
    "url": "https://doi.org/10.1109/TVCG.2013.226",
    "authors": [16, 0, 63, 64, 15],
    "links": [
      {
        "name": "Website",
        "link": "http://vgc.poly.edu/projects/taxivis/"
      },
      {
        "name": "Presentation",
        "file": "files/slides/2013-TaxiVis-TVCG.pdf"
      },
      {
        "name": "Video 1",
        "link": "https://vimeo.com/599109085"
      },
      {
        "name": "Video 2",
        "link": "https://vimeo.com/674442679"
      }
    ]
  },
  {
    "id": 6,
    "title": "SimilarityExplorer: A Visual Inter-Comparison Tool for  Multifaceted Climate Data",
    "venue_id": 17,
    "venue": "CGF",
    "web_name": "SimilarityExplorer",
    "year": 2014,
    "bibtext": "2014-SimilarityExplorer",
    "pdf": "files/papers/2014-SimilarityExplorer-CGF.pdf",
    "thumbnail": "images/thumbs/2014-SimilarityExplorer.png",
    "figure": "images/figures/2014-SimilarityExplorer.png",
    "caption": "",
    "start_page": 341,
    "end_page": 350,
    "volume": 33,
    "issue": 3,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Inter-comparison and similarity analysis to gauge consensus among multiple simulation models is a critical visualization problem for understanding climate change patterns. Climate models, specifically, Terrestrial Biosphere Models (TBM) represent time and space variable ecosystem processes, like, simulations of photosynthesis and respiration, using algorithms and driving variables such as climate and land use. While it is widely accepted that interactive visualization can enable scientists to better explore model similarity from different perspectives and different granularity of space and time, currently there is a lack of such visualization tools. In this paper we present three main contributions. First, we propose a domain characterization for the TBM community by systematically defining the domain-specific intents for analyzing model similarity and characterizing the different facets of the data. Second, we define a classification scheme for combining visualization tasks and multiple facets of climate model data in one integrated framework, which can be leveraged for translating the tasks into the visualization design. Finally, we present SimilarityExplorer, an exploratory visualization tool that facilitates similarity comparison tasks across both space and time through a set of coordinated multiple views. We present two case studies from three climate scientists, who used our tool for a month for gaining scientific insights into model similarity. Their experience and results validate the effectiveness of our tool.",
    "note": "",
    "pub_date": "2014-06-24",
    "url": "https://dl.acm.org/doi/10.5555/2854210.2854257",
    "authors": [0, 65, 66, 67, 68, 69, 70, 15],
    "links": [
      {
        "name": "Presentation",
        "file": "files/slides/2014-SimilarityExplorer-CGF.pdf"
      },
      {
        "name": "Video",
        "link": "https://vimeo.com/599111225"
      }
    ]
  },
  {
    "id": 7,
    "title": "Riding from Urban Data to Insight Using New York City Taxis",
    "venue_id": 16,
    "venue": "DataEngBull",
    "web_name": "TaxiInsights",
    "year": 2014,
    "bibtext": "2014-TaxiInsights",
    "pdf": "files/papers/2014-TaxiInsights-DataEngBull.pdf",
    "thumbnail": "images/thumbs/2014-TaxiInsights.png",
    "figure": "images/figures/2014-TaxiInsights.png",
    "caption": "",
    "start_page": 43,
    "end_page": 55,
    "volume": 37,
    "issue": 4,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "About half of humanity lives in urban environments today and that number will grow to 80% by the middle of this century. Cities are thus the loci of resource consumption, of economic activity, and of innovation. Given our increasing ability to collect, transmit, store, and analyze data, there is a great opportunity to better understand cities, and enable them to deliver services efficiently and sustainably while keeping their citizens safe, healthy, prosperous, and well-informed. But making sense of all the data available is hard. Currently, urban data exploration is often limited to confirmatory analyses consisting of batch-oriented queries and the exploration of well-defined questions over specific regions. The lack of interactivity makes this process both time-consuming and cumbersome. This problem is compounded in the presence of big, multivariate spatio-temporal data, which is ubiquitous in urban environments. Another challenge comes from the need to empower social scientists, policy makes and urban residents who lack computer science expertise to leverage these data. In this paper, we give an overview of our recent work on techniques that combine data management and visualization to enable a broad set of users to interactively explore large, spatio-temporal data. We describe a visual query interface that simplifies the process of specifying spatio-temporal queries as well as new indexing technique that enables these queries to be evaluated at interactive rates. We also present a scalable framework that applies computational topology to automatically find interesting data slices so as to help guide users in the exploratory process.",
    "note": "",
    "pub_date": "2014-12-01",
    "url": "http://sites.computer.org/debull/A14dec/p43.pdf",
    "authors": [64, 15, 63, 71, 16, 0]
  },
  {
    "id": 8,
    "title": "Visual Reconciliation of Alternative Similarity Spaces in Climate Modeling",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "VisualReconciliation",
    "year": 2014,
    "bibtext": "2014-VisualReconciliation",
    "pdf": "files/papers/2014-VisualReconciliation-TVCG.pdf",
    "thumbnail": "images/thumbs/2014-VisualReconciliation.png",
    "figure": "images/figures/2014-VisualReconciliation.png",
    "caption": "Iterative visual reconciliation of groupings based on climate model structure and model output.   Visual inspection ofsimilarity coupled with an underlying computation model facilitates iterative refinement of the groups and flexible exploration ofthe importance of the different parameters.",
    "start_page": 1923,
    "end_page": 1932,
    "volume": 20,
    "issue": 12,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Visual data analysis often requires grouping of data objects based on their similarity. In many application domains researchers use algorithms and techniques like clustering and multidimensional scaling to extract groupings from data. While extracting these groups using a single similarity criteria is relatively straightforward, comparing alternative criteria poses additional challenges. In this paper we define visual reconciliation as the problem of reconciling multiple alternative similarity spaces through visualization and interaction. We derive this problem from our work on model comparison in climate science where climate modelers are faced with the challenge of making sense of alternative ways to describe their models: one through the output they generate, another through the large set of properties that describe them. Ideally, they want to understand whether groups of models with similar spatio-temporal behaviors share similar sets of criteria or, conversely, whether similar criteria lead to similar behaviors. We propose a visual analytics solution based on linked views, that addresses this problem by allowing the user to dynamically create, modify and observe the interaction among groupings, thereby making the potential explanations apparent. We present case studies that demonstrate the usefulness of our technique in the area of climate science.",
    "note": "",
    "pub_date": "2014-12-01",
    "url": "http://dx.doi.org/10.1109/TVCG.2014.2346755",
    "authors": [0, 65, 66, 67, 68, 72, 69, 70, 15],
    "links": [
      {
        "name": "Website",
        "link": "http://vgc.poly.edu/projects/VisualReconciliation/"
      },
      {
        "name": "Presentation",
        "file": "files/slides/2014-VisualReconciliation-TVCG.pdf"
      },
      {
        "name": "Video",
        "link": "https://vimeo.com/599111804"
      }
    ]
  },
  {
    "id": 9,
    "title": "Exploring Traffic Dynamics in Urban Environments Using Vector-Valued Functions",
    "venue_id": 17,
    "venue": "CGF",
    "web_name": "TrafficFlow",
    "year": 2015,
    "bibtext": "2015-TrafficFlow",
    "pdf": "files/papers/2015-TrafficFlow-CGF.pdf",
    "thumbnail": "images/thumbs/2015-TrafficFlow.png",
    "figure": "images/figures/2015-TrafficFlow.png",
    "caption": "",
    "start_page": 161,
    "end_page": 170,
    "volume": 34,
    "issue": 3,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "The traffic infrastructure greatly impacts the quality of life in urban environments. To optimize this infrastructure, engineers and decision makers need to explore traffic data. In doing so, they face two important challenges: the sparseness of speed sensors that cover only a limited number of road segments, and the complexity of traffic patterns they need to analyze. In this paper we take a first step at addressing these challenges. We use New York City (NYC) taxi trips as sensors to capture traffic information. While taxis provide substantial coverage of the city, the data captured about taxi trips contain neither the location of taxis at frequent intervals nor their routes. We propose an efficient traffic model to derive speed and direction information from these data, and show that it provides reliable estimates. Using these estimates, we define a time-varying vector-valued function on a directed graph representing the road network, and adapt techniques used for vector fields to visualize the traffic dynamics. We demonstrate the utility of our technique in several case studies that reveal interesting mobility patterns in NYC’s traffic. These patterns were validated by experts from NYC’s Department of Transportation and the NYC Taxi & Limousine Commission, who also provided interesting insights into these results.",
    "note": "",
    "pub_date": "2015-07-20",
    "url": "https://doi.org/10.1111/cgf.12628",
    "authors": [0, 71, 63, 73, 64, 15],
    "links": [
      {
        "name": "Website",
        "link": "http://vgc.poly.edu/projects/TrafficFlow/"
      },
      {
        "name": "Presentation",
        "file": "files/slides/2015-TrafficFlow-CGF.pdf"
      },
      {
        "name": "Video",
        "link": "https://vimeo.com/599112703"
      },
      {
        "name": "Appendix",
        "file": "files/appendix/2015-TrafficFlow-CGF.pdf"
      }
    ]
  },
  {
    "id": 10,
    "title": "Bridging Theory with Practice: An Exploratory Study of Visualization Use and Design for Climate Model Comparison",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "ExploratoryStudy",
    "year": 2015,
    "bibtext": "2015-ExploratoryStudy",
    "pdf": "files/papers/2015-ExploratoryStudy-TVCG.pdf",
    "thumbnail": "images/thumbs/2015-ExploratoryStudy.png",
    "figure": "images/figures/2015-ExploratoryStudy.png",
    "caption": "",
    "start_page": 996,
    "end_page": 1014,
    "volume": 21,
    "issue": 9,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Evaluation methodologies in visualization have mostly focused on how well the tools and techniques cater to the analytical needs of the user. While this is important in determining the effectiveness of the tools and advancing the state-of-the-art in visualization research, a key area that has mostly been overlooked is how well established visualization theories and principles are instantiated in practice. This is especially relevant when domain experts, and not visualization researchers, design visualizations for analysis of their data or for broader dissemination of scientific knowledge. There is very little research on exploring the synergistic capabilities of cross-domain collaboration between domain experts and visualization researchers. To fill this gap, in this paper we describe the results of an exploratory study of climate data visualizations conducted in tight collaboration with a pool of climate scientists. The study analyzes a large set of static climate data visualizations for identifying their shortcomings in terms of visualization design. The outcome of the study is a classification scheme that categorizes the design problems in the form of a descriptive taxonomy. The taxonomy is a first attempt for systematically categorizing the types, causes, and consequences of design problems in visualizations created by domain experts. We demonstrate the use of the taxonomy for a number of purposes, such as, improving the existing climate data visualizations, reflecting on the impact of the problems for enabling domain experts in designing better visualizations, and also learning about the gaps and opportunities for future visualization research. We demonstrate the applicability of our taxonomy through a number of examples and discuss the lessons learnt and implications of our findings.",
    "note": "",
    "pub_date": "2015-09-01",
    "url": "https://doi.org/10.1109/TVCG.2015.2413774",
    "authors": [65, 0, 66, 69, 70, 15],
    "links": [
      {
        "name": "Website",
        "link": "http://vgc.poly.edu/projects/ClimateVisEvaluation/"
      }
    ]
  },
  {
    "id": 11,
    "title": "Using Maximum Topology Matching to Explore Differences in Species Distribution Models",
    "venue_id": 15,
    "venue": "SciVis",
    "web_name": "TopoMatching",
    "year": 2015,
    "bibtext": "2015-TopoMatching",
    "pdf": "files/papers/2015-TopoMatching-SciVis.pdf",
    "thumbnail": "images/thumbs/2015-TopoMatching.png",
    "figure": "images/figures/2015-TopoMatching.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.",
    "note": "",
    "pub_date": "2015-10-25",
    "url": "https://doi.org/10.1109/SciVis.2015.7429486",
    "authors": [0, 71, 74, 75, 15],
    "links": [
      {
        "name": "Presentation",
        "file": "files/slides/2015-TopoMatching-SciVis.pdf"
      },
      {
        "name": "Video",
        "link": "https://vimeo.com/599112149"
      }
    ]
  },
  {
    "id": 12,
    "title": "Reducing the Analytical Bottleneck for Domain Scientists: Lessons from a Climate Data Visualization Case Study",
    "venue_id": 14,
    "venue": "CiSE",
    "web_name": "ReducingBottleneck",
    "year": 2016,
    "bibtext": "2016-ReducingBottleneck",
    "pdf": "files/papers/2016-ReducingBottleneck-CiSE.pdf",
    "thumbnail": "images/thumbs/2016-ReducingBottleneck.png",
    "figure": "images/figures/2016-ReducingBottleneck.png",
    "caption": "Reducing the analytical bottleneck in scientific data analysis through iterative exploration of large-scale data. In comparing (a) the state of the art and (b) a bottleneck reduction, we see the time taken for analysis and deriving insights being significantly reduced, leading to a richer exploration of alternative hypotheses on the fly, and consequently, a faster and greater return on investment of analysis time for domain scientists.",
    "start_page": 92,
    "end_page": 100,
    "volume": 18,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "The gap between large-scale data production rate and the rate of generation of data-driven scientific insights has led to an analytical bottleneck in scientific domains like climate, biology, and so on. This is primarily due to the lack of innovative analytical tools that can help scientists efficiently analyze and explore alternative hypotheses about the data and communicate their findings effectively to a broad audience. In this article, by reflecting on a set of successful collaborative research efforts between with a group of climate scientists and visualization researchers, the 'authors' introspect how interactive visualization can help reduce the analytical bottleneck for domain scientists.",
    "note": "",
    "pub_date": "2016-01-01",
    "url": "https://doi.org/10.1109/MCSE.2016.7",
    "authors": [65, 0, 70, 15]
  },
  {
    "id": 13,
    "title": "Reverse-Engineering Visualizations: Recovering Visual Encodings from Chart Images",
    "venue_id": 17,
    "venue": "CGF",
    "web_name": "ReverseEngineeringVis",
    "year": 2017,
    "bibtext": "2017-ReverseEngineeringVis",
    "pdf": "files/papers/2017-ReverseEngineeringVis-CGF.pdf",
    "thumbnail": "images/thumbs/2017-ReverseEngineeringVis.png",
    "figure": "images/figures/2017-ReverseEngineeringVis.png",
    "caption": "",
    "start_page": 353,
    "end_page": 363,
    "volume": 36,
    "issue": 3,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "We investigate how to automatically recover visual encodings for a chart image, primarily using inferred text elements. We contribute an end-to-end pipeline which takes a bitmap image as input and returns a visual encoding specification as output. We present a text analysis pipeline which detects text elements in a chart, classifies their role (e.g., chart title, x-axis label, y-axis title, etc.), and recovers the text content using optical character recognition. We also train a Convolutional Neural Network for mark type classification. Using the identified text elements and graphical mark type, we can then infer the encoding specification of an input chart image. We evaluate our techniques on three chart corpora: a set of automatically labeled charts generated using Vega, charts from the Quartz news website, and charts extracted from academic papers. We demonstrate accurate automatic inference of text elements, mark types, and chart specifications across a variety of input chart types.",
    "note": "",
    "pub_date": "2017-07-04",
    "url": "https://doi.org/10.1111/cgf.13193",
    "authors": [0, 76],
    "links": [
      {
        "name": "Code",
        "link": "https://github.com/visual-ds/rev"
      },
      {
        "name": "Appendix",
        "file": "files/appendix/2017-ReverseEngineeringVis-CGF.pdf"
      }
    ]
  },
  {
    "id": 14,
    "title": "Extracting Visual Encodings from Map Chart Images with Color-encoded Scalar Values",
    "venue_id": 13,
    "venue": "SIBGRAPI",
    "web_name": "ExtractingMapEncoding",
    "year": 2018,
    "bibtext": "2018-ExtractingMapEncoding",
    "pdf": "files/papers/2018-ExtractingMapEncoding-SIBGRAPI.pdf",
    "thumbnail": "images/thumbs/2018-ExtractingMapEncoding.png",
    "figure": "images/figures/2018-ExtractingMapEncoding.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Map charts are used in diverse domains to show geographic data (e.g., climate research, oceanography, business analysis, etc.). These charts can be found in news articles, scientific papers, and on the Web. However, many map charts are available only as bitmap images, hindering machine interpretation of the visualized data for indexing and reuse. We propose a pipeline to recover both the visual encodings and underlying data from bitmap images of geographic maps with color-encoded scalar values. We evaluate our results using map images from scientific documents, achieving high accuracy along each step of our proposal. In addition, we present two applications: data extraction and map reprojection to enable improved visual representations of map charts.",
    "note": "",
    "pub_date": "2018-01-10",
    "url": "https://doi.org/10.1109/SIBGRAPI.2018.00025",
    "authors": [20, 17, 76, 0],
    "links": [
      {
        "name": "Video 1",
        "link": "https://vimeo.com/599113747"
      },
      {
        "name": "Video 2",
        "link": "https://vimeo.com/599113082"
      }
    ]
  },
  {
    "id": 15,
    "title": "Extracting and Retargeting Color Mappings from Bitmap Images of Visualizations",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "ExtractingColorMappings",
    "year": 2018,
    "bibtext": "2018-ExtractingColorMappings",
    "pdf": "files/papers/2018-ExtractingColorMappings-TVCG.pdf",
    "thumbnail": "images/thumbs/2018-ExtractingColorMappings.png",
    "figure": "images/figures/2018-ExtractingColorMappings.png",
    "caption": "Automatic extraction and redesign of color mappings for a geographic heatmap. The bitmap image on the left uses a questionablerainbow color palette. Our methods automatically recover the color mapping, enabling applications such as automatic recoloring. Thegenerated image on the right replaces the original color palette with a perceptually-motivated diverging color scheme.",
    "start_page": 637,
    "end_page": 646,
    "volume": 24,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Visualization designers regularly use color to encode quantitative or categorical data. However, visualizations \"in the wild\" often violate perceptual color design principles and may only be available as bitmap images. In this work, we contribute a method to semi-automatically extract color encodings from a bitmap visualization image. Given an image and a legend location, we classify the legend as describing either a discrete or continuous color encoding, identify the colors used, and extract legend text using OCR methods. We then combine this information to recover the specific color mapping. Users can also correct interpretation errors using an annotation interface. We evaluate our techniques using a corpus of images extracted from scientific papers and demonstrate accurate automatic inference of color mappings across a variety of chart types. In addition, we present two applications of our method: automatic recoloring to improve perceptual effectiveness, and interactive overlays to enable improved reading of static visualizations.",
    "note": "",
    "pub_date": "2018-08-29",
    "url": "https://doi.org/10.1109/TVCG.2017.2744320",
    "authors": [0, 20, 76]
  },
  {
    "id": 16,
    "title": "The Effect of Color Scales on Climate Scientists' Objective and Subjective Performance in Spatial Data Analysis Tasks",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "ColorStudy",
    "year": 2020,
    "bibtext": "2020-ColorStudy",
    "pdf": "files/papers/2020-ColorStudy-TVCG.pdf",
    "thumbnail": "images/thumbs/2020-ColorStudy.png",
    "figure": "images/figures/2020-ColorStudy.png",
    "caption": "",
    "start_page": 1577,
    "end_page": 1591,
    "volume": 26,
    "issue": 3,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Geographical maps encoded with rainbow color scales are widely used for spatial data analysis in climate science, despite evidence from the visualization literature that they are not perceptually optimal. We present a controlled user study that compares the effect of color scales on performance accuracy for climate-modeling tasks using pairs of continuous geographical maps generated using climatological metrics. For each pair of maps, 39 scientist-observers judged: i) the magnitude of their difference, ii) their degree of spatial similarity, and iii) the region of greatest dissimilarity between them. Besides the rainbow color scale, two other continuous color scales were chosen such that all three of them covaried two dimensions (luminance monotonicity and hue banding), hypothesized to have an impact on visual performance. We also analyzed subjective performance measures, such as user confidence, perceived accuracy, preference, and familiarity in using the different color scales. We found that monotonic luminance scales produced significantly more accurate judgments of magnitude difference but were not superior in spatial comparison tasks, and that hue banding had differential effects based on the task and conditions. Scientists expressed the highest preference and perceived confidence and accuracy with the rainbow, despite its poor performance on the magnitude comparison tasks.",
    "note": "",
    "pub_date": "2020-10-17",
    "url": "https://doi.org/10.1109/TVCG.2018.2876539",
    "authors": [65, 0, 77, 78, 70, 15],
    "links": [
      {
        "name": "Suplement",
        "link": "https://vgc.poly.edu/~jpocom/pubs/colorStudy2020Supplemental.zip"
      },
      {
        "name": "Video",
        "link": "https://vimeo.com/599114269"
      }
    ]
  },
  {
    "id": 17,
    "title": "Mirante: A Visualization Tool for Analyzing Urban Crimes",
    "venue_id": 13,
    "venue": "SIBGRAPI",
    "web_name": "Mirante",
    "year": 2020,
    "bibtext": "2020-Mirante",
    "pdf": "files/papers/2020-Mirante-SIBGRAPI.pdf",
    "thumbnail": "images/thumbs/2020-Mirante.png",
    "figure": "images/figures/2020-Mirante.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Visualization assisted crime analysis tools used by public security agencies are usually designed to explore large urban areas, relying on grid-based heatmaps to reveal spatial crime distribution in whole districts, regions, and neighborhoods. Therefore, those tools can hardly identify micro-scale patterns closely related to crime opportunity, whose understanding is fundamental to the planning of preventive actions. Enabling a combined analysis of spatial patterns and their evolution over time is another challenge faced by most crime analysis tools. In this paper, we present Mirante, a crime mapping visualization system that allows spatiotemporal analysis of crime patterns in a street-level scale. In contrast to conventional tools, Mirante builds upon street-level heatmaps and other visualization resources that enable spatial and temporal pattern analysis, uncovering fine-scale crime hotspots, seasonality, and dynamics over time. Mirante has been developed in close collaboration with domain experts, following rigid requirements as scalability and versatile to be implemented in large and medium-sized cities. We demonstrate the usefulness of Mirante throughout case studies run by domain experts using real data sets from cities with different characteristics. With the help of Mirante, the experts were capable of diagnosing how crime evolves in specific regions of the cities while still being able to raise hypotheses about why certain types of crime show up.",
    "note": "",
    "pub_date": "2020-11-25",
    "url": "https://doi.org/10.1109/SIBGRAPI51738.2020.00028",
    "authors": [12, 17, 79, 0, 80, 81, 18],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/674440555"
      },
      {
        "name": "Best Paper Award in Visualization",
        "file": "files/docs/2020-Mirante-SIBGRAPI-BestPaper.pdf"
      }
    ]
  },
  {
    "id": 18,
    "title": "CrimAnalyzer: Understanding Crime Patterns in São Paulo",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "CrimAnalyzer",
    "year": 2021,
    "bibtext": "2021-CrimAnalyzer",
    "pdf": "files/papers/2021-CrimAnalyzer-TVCG.pdf",
    "thumbnail": "images/thumbs/2021-CrimAnalyzer.png",
    "figure": "images/figures/2021-CrimAnalyzer.png",
    "caption": "CrimAnalyzer system: the spatial and temporal interactive views enable the exploration of local regions while revealing their criminal patternsover time.",
    "start_page": 2313,
    "end_page": 2328,
    "volume": 27,
    "issue": 4,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "São Paulo is the largest city in South America, with crime rates that reflect its size. The number and type of crimes vary considerably around the city, assuming different patterns depending on urban and social characteristics of each particular location. Previous works have mostly focused on the analysis of crimes with the intent of uncovering patterns associated to social factors, seasonality, and urban routine activities. Therefore, those studies and tools are more global in the sense that they are not designed to investigate specific regions of the city such as particular neighborhoods, avenues, or public areas. Tools able to explore specific locations of the city are essential for domain experts to accomplish their analysis in a bottom-up fashion, Revealing how urban features related to mobility, passersby behavior, and presence of public infrastructures (e.g., terminals of public transportation and schools) can influence the quantity and type of crimes. In this paper, we present CrimAnalyzer, a visual analytic tool that allows users to study the behavior of crimes in specific regions of a city. The system allows users to identify local hotspots and the pattern of crimes associated to them, while still showing how hotspots and corresponding crime patterns change over time. CrimAnalyzer has been developed from the needs of a team of experts in criminology and deals with three major challenges: i) flexibility to explore local regions and understand their crime patterns, ii) identification of spatial crime hotspots that might not be the most prevalent ones in terms of the number of crimes but that are important enough to be investigated, and iii) understand the dynamic of crime patterns over time. The effectiveness and usefulness of the proposed system are demonstrated by qualitative and quantitative comparisons as well as by case studies run by domain experts involving real data. The experiments show the capability of CrimAnalyzer in identifying crime-related phenomena.",
    "note": "",
    "pub_date": "2021-01-04",
    "url": "https://doi.org/10.1109/TVCG.2019.2947515",
    "authors": [12, 79, 0, 82, 80, 15, 81, 18],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/599115203"
      }
    ]
  },
  {
    "id": 19,
    "title": "A Comparative Study of WHO and WHEN Prediction Approaches for Early Identification of University Students at Dropout Risk",
    "venue_id": 18,
    "venue": "CLEI",
    "web_name": "DropoutAnalysis",
    "year": 2021,
    "bibtext": "2021-DropoutAnalysis",
    "pdf": "files/papers/2021-DropoutAnalysis-CLEI.pdf",
    "thumbnail": "images/thumbs/2021-DropoutAnalysis.png",
    "figure": "images/figures/2021-DropoutAnalysis.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Reducing the students' dropout is one of the biggest challenges faced by educational institutions, especially in underdeveloped countries. Identification of the student with the highest risk of dropping out is generally used to apply corrective actions (WHO). Therefore, it is also important to determine WHEN a student will drop out, which is fundamental to planning preventive actions. In this work, we perform a study to quantitatively compare several approaches to address the early identification of dropout students in universities. We categorize our study into three main methods families, i.e., analytical methods, traditional classification methods, and probabilistic methods. The first is exploited at preprocessing step for selecting significant variables into the dropout identification task. The second uses machine learning models to classify students into dropout prone or non-dropout prone classes. The third family uses survival models to determine when the student would desert. To evaluate the predictive capacity of the classification models, the Kappa coefficient was incorporated into the usual machine learning metrics and shows that Kappa is handy for evaluating performance in unbalanced data. Similarly, in the survival models, the concordance index was applied to evaluate the predictive capacity. Our approach was applied over a real data set of Peruvian university graduate students to identify when and who will drop out.",
    "note": "",
    "pub_date": "2021-08-01",
    "url": "",
    "authors": [83, 12, 84, 85, 0, 17]
  },
  {
    "id": 20,
    "title": "CriPAV: Street-Level Crime Patterns Analysis and Visualization",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "CriPAV",
    "year": 2021,
    "bibtext": "2021-CriPAV",
    "pdf": "files/papers/2021-CriPAV-TVCG.pdf",
    "thumbnail": "images/thumbs/2021-CriPAV.png",
    "figure": "images/figures/2021-CriPAV.png",
    "caption": "",
    "start_page": 4000,
    "end_page": 4015,
    "volume": 28,
    "issue": 12,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Extracting and analyzing crime patterns in big cities is a challenging spatiotemporal problem. The hardness of the problem is linked to two main factors, the sparse nature of the crime activity and its spread in large spatial areas. Sparseness hampers most time series (crime time series) comparison methods from working properly, while the handling of large urban areas tends to render the computational costs of such methods impractical. Visualizing different patterns hidden on crime time series data is another issue in this context, mainly due to the number of patterns that can show up from the time series analysis. In this paper, we present a new methodology to deal with the issues above, enabling the analysis of spatiotemporal crime patterns in a street-level of detail. Our approach is made up of two main components designed to handle the spatial sparsity and spreading of crimes in large areas of the city. The first component relies on a stochastic mechanism from which one can visually analyze probableXintensive crime hotspots. Such analysis reveals important patterns that can not be observed in the typical intensity-based hotspot visualization. The second component builds upon a deep learning mechanism to embed crime time series in Cartesian space. From the embedding, one can identify spatial locations where the crime time series have similar behavior. The two components have been integrated into a web-based analytical tool called CriPAV (Crime Pattern Analysis and Visualization), which enables global as well as a street-level view of crime patterns. Developed in close collaboration with domain experts, CriPAV has been validated through a set of case studies with real crime data in São Paulo - Brazil. The provided experiments and case studies reveal the effectiveness of CriPAV in identifying patterns such as locations where crimes are not intense but highly probable to occur as well as locations that are far apart from each other but bear similar crime patterns.",
    "note": "",
    "pub_date": "2021-08-26",
    "url": "https://doi.org/10.1109/TVCG.2021.3111146",
    "authors": [12, 8, 0, 80, 15, 81, 18],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/607668077"
      }
    ]
  },
  {
    "id": 21,
    "title": "An Online and Nonuniform Timeslicing Method for Network Visualisation",
    "venue_id": 20,
    "venue": "C&G",
    "web_name": "OnlineTimeslicing",
    "year": 2021,
    "bibtext": "2021-OnlineTimeslicing",
    "pdf": "files/papers/2021-OnlineTimeslicing-C&G.pdf",
    "thumbnail": "images/thumbs/2021-OnlineTimeslicing.png",
    "figure": "images/figures/2021-OnlineTimeslicing.png",
    "caption": "",
    "start_page": 170,
    "end_page": 182,
    "volume": 97,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Visual analysis of temporal networks comprises an effective way to understand the network dynamics. It facilitates the identification of patterns, anomalies, and other network properties, thus resulting in fast decision making. The amount of data in real-world networks, however, may result in a layout with high visual clutter due to edge overlapping. This is particularly relevant in the so-called streaming networks, in which edges are continuously arriving (online) and in non-stationary distribution. All three network dimensions, namely node, edge, and time, can be manipulated to reduce such clutter and improve readability. This paper presents an online and nonuniform timeslicing method that enhances temporal and streaming network analyses. We conducted experiments using two real-world networks to compare our method against uniform and nonuniform timeslicing strategies. The results show that our method automatically selects timeslices that effectively reduce visual clutter in periods with bursts of events. As a consequence, decision making based on the identification of global temporal patterns becomes faster and more reliable.",
    "note": "",
    "pub_date": "2021-06-01",
    "url": "https://doi.org/10.1016/j.cag.2021.04.006",
    "authors": [10, 23, 87, 88],
    "links": [
      {
        "name": "Data",
        "file": "files/data/2021-OnlineTimeslicing-C&G.pdf"
      }
    ]
  },
  {
    "id": 22,
    "title": "DRIFT: A Visual Analytic Tool for Scientific Literature Exploration Based on Textual and Image Content",
    "venue_id": 13,
    "venue": "SIBGRAPI",
    "web_name": "DRIFT",
    "year": 2021,
    "bibtext": "2021-DRIFT",
    "pdf": "files/papers/2021-DRIFT-SIBGRAPI.pdf",
    "thumbnail": "images/thumbs/2021-DRIFT.png",
    "figure": "images/figures/2021-DRIFT.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Exploring digital libraries of scientific articles is an essential task for any research community. The typical approach is to query the articles' data based on keywords and manually inspect the resulting list of documents to identify which papers are of interest. Besides being time-consuming, such a manual inspection is quite limited, as it can hardly provide an overview of articles with similar topics or subjects. Moreover, accomplishing queries based on content other than keywords is rarely doable, impairing finding documents with similar images. In this paper, we propose a visual analytic methodology for exploring and analyzing scientific document collections that consider the content of scientific documents, including images. The proposed approach relies on a combination of Content-Based Image Retrieval (CBIR) and multidimensional projection to map the documents to a visual space based on their similarity, thus enabling an interactive exploration. Additionally, we enable visual resources to display complementary information on selected documents that uncover hidden patterns and semantic relations. We show the effectiveness of our methodology through two case studies and a user evaluation, which attest to the usefulness of the proposed framework in exploring scientific document collections.",
    "note": "",
    "pub_date": "2021-10-08",
    "url": "",
    "authors": [89, 0, 90, 91, 18, 17],
    "links": [
      {
        "name": "Honorable Mention in Visualization",
        "file": "files/docs/2021-DRIFT-SIBGRAPI-HonorableMention.pdf"
      },
      {
        "name": "Video 1",
        "link": "https://vimeo.com/623563608"
      },
      {
        "name": "Video 2",
        "link": "https://vimeo.com/623626417"
      }
    ]
  },
  {
    "id": 23,
    "title": "Urban Perception: Can we Understand Why a Street is Safe?",
    "venue_id": 21,
    "venue": "MICAI",
    "web_name": "UrbanPerceptionSafe",
    "year": 2021,
    "bibtext": "2021-UrbanPerceptionSafe",
    "pdf": "files/papers/2021-UrbanPerceptionSafe-MICAI.pdf",
    "thumbnail": "images/thumbs/2021-UrbanPerceptionSafe.png",
    "figure": "images/figures/2021-UrbanPerceptionSafe.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "The importance of urban perception computing is relatively growing in machine learning, particularly in related areas to Urban Planning and Urban Computing. This held of study focuses on developing systems to analyze and map discriminant characteristics that might directly impact the city's perception. In other words, it seeks to identify and extract discriminant components to define the behavior of a city's perception. This work will perform a street-level analysis to understand safety perception based on the \"visual components\". As our result, we present our experimental evaluation regarding the in uence and impact of those visual components on the safety criteria and further discuss how to properly choose confidence on safe or unsafe measures concerning the perceptional scores on the city street levels analysis.",
    "note": "",
    "pub_date": "2021-09-30",
    "url": "https://link.springer.com/chapter/10.1007/978-3-030-89817-5_21",
    "authors": [4, 9, 0]
  },
  {
    "id": 24,
    "title": "iStar (i*): An Interactive Star Coordinates Approach for High-Dimensional Data Exploration",
    "venue_id": 13,
    "venue": "SIBGRAPI",
    "web_name": "IStar",
    "year": 2016,
    "bibtext": "2016-IStar",
    "pdf": "files/papers/2016-IStar-SIBGRAPI.pdf",
    "thumbnail": "images/thumbs/2016-IStar.png",
    "figure": "images/figures/2016-IStar.png",
    "caption": "",
    "start_page": 107,
    "end_page": 118,
    "volume": 60,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Star Coordinates is an important visualization method able to reveal patterns and groups from multidimensional data while still showing the impact of data attributes in the formation of such patterns and groups. Despite its usefulness, Star Coordinates bears limitations that impair its use in several scenarios. For instance, when the number of data dimensions is high, the resulting visualization becomes cluttered, hampering the joint analysis of attribute importance and group/pattern formation. In this paper, we propose a novel method that renders Star Coordinates a feasible alternative to analyze high-dimensional data. The proposed method relies on a clustering mechanism to group attributes in order to mitigate visual clutter. Clustering can be performed automatically as well as interactively, allowing the analysis of how particular groups of attributes impact on the radial layout, thus assisting users in the understanding of data. The effectiveness of our approach is shown through a set of experiments and case studies, which attest its usefulness in practical applications.",
    "note": "",
    "pub_date": "2016-11-01",
    "url": "https://www.sciencedirect.com/science/article/abs/pii/S0097849316301054",
    "authors": [12, 18, 17]
  },
  {
    "id": 25,
    "title": "Trajectory Anomaly Detection based on Similarity Analysis",
    "venue_id": 18,
    "venue": "CLEI",
    "web_name": "TrajectoryAnomaly",
    "year": 2021,
    "bibtext": "2021-TrajectoryAnomaly",
    "pdf": "files/papers/2021-TrajectoryAnomaly-CLEI.pdf",
    "thumbnail": "images/thumbs/2021-TrajectoryAnomaly.png",
    "figure": "images/figures/2021-TrajectoryAnomaly.png",
    "caption": "",
    "start_page": 1,
    "end_page": 10,
    "volume": 1,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Automatic trajectory processing has multiple applications, mainly due to the wide availability of the data. Trajectory data have a significant practical value, making possible the modeling of various problems such as surveillance and tracking devices, detect anomaly trajectories, identifying illegal and adverse activity. In this study, we show a comparative analysis of the performance of two descriptors to detect anomaly trajectories. We define Wavelet and Fourier transforms as trajectory descriptors to generate characteristics and subsequently detect anomalies. The experiments emphasize performance in the description in the coefficient feature space. For that, we used unsupervised learning, specifically clustering techniques, to generate subsets and identify which are irregular. The implications of the study demonstrate that it is possible to use descriptors in trajectories for automatic anomaly detection and the use of unsupervised learning methods that automatically segment the required information. The performance and comparative analysis of our study are demonstrated through experiments and a case study considering synthetic and real data sets that leave evidence of our contribution.",
    "note": "",
    "pub_date": "2021-10-29",
    "url": "",
    "authors": [92, 93, 94, 12]
  },
  {
    "id": 26,
    "title": "Quantifying Urban Safety Perception on Street View Images",
    "venue_id": 22,
    "venue": "WIIAT",
    "web_name": "UrbanPerceptionQuantify",
    "year": 2021,
    "bibtext": "2021-UrbanPerceptionQuantify",
    "pdf": "files/papers/2021-UrbanPerceptionQuantify-WIIAT.pdf",
    "thumbnail": "images/thumbs/2021-UrbanPerceptionQuantify.png",
    "figure": "images/figures/2021-UrbanPerceptionQuantify.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "In the last 40 years, Urban perception has become an important research area covering several fields, such as criminology, psychology, urban planning, Broken windows theory. It aims to analyze and interpret the behavior of the perception in cities. Urban perception focuses on understanding urban environments based on the characteristics of the city. With the rapidly increasing data availability and highly scalable data collection methods powered by modern web services, new techniques from other domains enabled the exploration of solutions to estimate urban perception (i.e., quantify urban perception autonomously). This work presents a methodology to explore the urban perception analysis task. The work relies on the benchmark dataset, Place Pulse. This dataset is used to perform our classification tasks concerning the category of safety in urban perception problems.",
    "note": "",
    "pub_date": "2021-12-14",
    "url": "",
    "authors": [4, 9, 0]
  },
  {
    "id": 27,
    "title": "17K-Graffiti: Spatial and Crime Data Assessments in São Paulo City",
    "venue_id": 23,
    "venue": "VISAPP",
    "web_name": "17KGraffiti",
    "year": 2022,
    "bibtext": "2022-17KGraffiti",
    "pdf": "files/papers/2022-17KGraffiti-VISAPP.pdf",
    "thumbnail": "images/thumbs/2022-17KGraffiti.png",
    "figure": "images/figures/2022-17KGraffiti.png",
    "caption": "Top: Geographical distributions of downloaded GSV images, and detected Graffiti; Bottom: crime against vehicle, and crime against pedestrian over 96 districts of São Paulo.",
    "start_page": 968,
    "end_page": 975,
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Graffiti is an inseparable element of most large cities. It is of critical value to recognize whether it is an artistry product or a distortion sign. This study develops a larger graffiti dataset containing a variety of graffiti types and annotated boundary boxes. We use this data to obtain a robust graffiti detection model. Compared with existing methods on the task, the proposed model achieves superior results. As a case study, the created model is evaluated on a vast number of street view images to localize graffiti incidence in the city of São Paulo, Brazil. We also validated our model using the case study data, and, again, the method achieved outstanding performance. The robustness of the technique enabled further analysis of the geographical distribution of graffiti. Considering graffiti as a spatial element of the city, we investigated its relation with crime occurrences. Relatively high correlation values were obtained between graffiti and crimes against pedestrians. Finally, this work raises many questions, such as the understanding of how these relationships change across the city according to the types of graffiti.",
    "note": "",
    "pub_date": "2022-02-06",
    "url": "https://doi.org/10.5220/0010883300003124",
    "authors": [9, 95, 4, 18, 15, 0],
    "links": [
      {
        "name": "Code",
        "link": "https://github.com/visual-ds/17K-Graffiti"
      },
      {
        "name": "Data",
        "link": "https://zenodo.org/record/5899631"
      }
    ]
  },
  {
    "id": 28,
    "title": "JamVis: Exploration and Visualization of Traffic Jams",
    "venue_id": 24,
    "venue": "EPJ-ST",
    "web_name": "JamVis",
    "year": 2022,
    "bibtext": "2022-JamVis",
    "pdf": "files/papers/2022-JamVis-EPJ-ST.pdf",
    "thumbnail": "images/thumbs/2022-JamVis.png",
    "figure": "images/figures/2022-JamVis.png",
    "caption": "",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Traffic jams are a significant problem in urban cities that cause pollution and waste fuel, money, and time. Therefore, there is an urgent need to build tools that enable authorities to monitor and understand traffic dynamics and their causes. However, exploring these large complex data presents a challenge to domain experts. This paper proposes JamVis, a web-based visual analytics framework that leverages Waze's multi-modal spatio-temporal data to this end. JamVis comprises two main components designed based on requirements elicited from domain experts. The first one supports the exploration of Waze's traffic jam information through multiple linked views. The second component allows identifying events through alerts reported by Waze users about different problems (e.g., potholes, floods, or heavy traffic). A new algorithm called TST-Clustering is introduced to perform event detection, which is an adaptation of the DB-Scan algorithm that allows clustering alerts by space, time, and type. Furthermore, to provide an overview of this algorithm's spatio-temporal results, we introduce a novel visualization called ST-Heatmap. JamVis is validated through three usage scenarios analyzing different events in Rio de Janeiro.",
    "note": "",
    "pub_date": "2022-01-27",
    "url": "",
    "authors": [21, 16, 0],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/673264404"
      }
    ]
  },
  {
    "id": 29,
    "title": "ChartText Linking Text with Charts in Documents",
    "venue_id": 11,
    "venue": "arXiv",
    "web_name": "ChartText",
    "year": 2022,
    "bibtext": "2022-ChartText",
    "pdf": "files/papers/2022-ChartText-arXiv.pdf",
    "thumbnail": "images/thumbs/2022-ChartText.png",
    "figure": "images/figures/2022-ChartText.png",
    "caption": "The application uses our proposed method to convert voice into visual guides or overlays on the chart.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Recent works show that interactive documents connecting text with visualizations facilitate reading comprehension. However, creating this type of content requires specialized knowledge. We present ChartText, a method that links text with visualizations in this work. Our approach supports documents that include bar charts, line charts, and scatter plots. ChartText receives the visual encoding of the visualization and its associated text as input. It then performs the linking in two stages: The matching stage creates individual links relating simple phrases between the text and the chart. Then, it combines the individual links according to the visual channels in the grouping stage, building more meaningful connections. We use two datasets to design and evaluate our method; the first comes from web documents (24 bar charts and texts) and the second from academic documents (25 bar charts, 25 line charts, and 25 scatter plots with their texts). Our experiments show that our method obtains F1 scores of 0.50 and 0.66 on both datasets. We can also use a semi-automatic approach correcting individual links; in this case, the scores rise to 0.68 and 0.84, respectively. To show the usefulness of our technique, we implement two proofs of concept. We create interactive documents using graphic overlays in the first one, facilitating the reading experience. We use voice instead of text to annotate charts in real-time in the second. For example, in a videoconference, our technique can automatically annotate a chart following the presenter’s description.",
    "note": "",
    "pub_date": "2022-01-13",
    "url": "https://arxiv.org/abs/2201.05043",
    "authors": [19, 0],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/manage/videos/669447193"
      },
      {
        "name": "Data",
        "file": "files/data/2022-ChartText-arXiv.zip"
      }
    ]
  },
  {
    "id": 30,
    "title": "Exploring Scientific Literature by Textual and Image Content using DRIFT",
    "venue_id": 20,
    "venue": "C&G",
    "web_name": "SciLitDRIFT",
    "year": 2022,
    "bibtext": "2022-SciLitDRIFT",
    "pdf": "files/papers/2022-SciLitDRIFT-C&G.pdf",
    "thumbnail": "images/thumbs/2022-SciLitDRIFT.png",
    "figure": "images/figures/2022-SciLitDRIFT.png",
    "caption": "",
    "start_page": 136,
    "end_page": 143,
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Digital libraries represent the most valuable resource for storing, querying, and retrieving scientific literature. Traditionally, the reader/analyst aims to compose a set of articles based on keywords, according to his/her preferences, and manually inspect the resulting list of documents. Except for the articles which share citations or common keywords, the results retrieved will be limited to those which fulfill a syntactic match. Besides, if instead of having an article as a reference, the user has an image, the process of finding and exploring articles with similar content becomes infeasible. This paper proposes a visual analytic methodology for exploring and analyzing scientific document collections that consider both textual and image content. The proposed technique relies on combining multiple Content-Based Image Retrieval (CBIR) components and multidimensional projection to map the documents to a visual space based on their similarity, thus enabling an interactive exploration. Moreover, we extend its analytical capabilities with visual resources to display complementary information on selected documents that uncover hidden patterns and semantic relations. We evidence the effectiveness of our methodology through three case studies and a user evaluation, which attest to its usefulness during the process of scientific collections exploration.",
    "note": "",
    "pub_date": "2022-02-11",
    "url": "https://doi.org/10.1016/j.cag.2022.02.005",
    "authors": [89, 2, 0, 18, 17],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/677947247"
      }
    ]
  },
  {
    "id": 31,
    "title": "LegalVis: Exploring and Inferring Precedent Citations in Legal Documents",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "LegalVis",
    "year": 2023,
    "bibtext": "2023-LegalVis",
    "pdf": "files/papers/2023-LegalVis-TVCG.pdf",
    "thumbnail": "images/thumbs/2023-LegalVis.png",
    "figure": "images/figures/2023-LegalVis.png",
    "caption": "",
    "start_page": 3105,
    "end_page": 3120,
    "volume": 29,
    "issue": 6,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "To reduce the number of pending cases and conflicting rulings in the Brazilian Judiciary, the National Congress amended the Constitution, allowing the Brazilian Supreme Court (STF) to create binding precedents (BPs), i.e., a set of understandings that both Executive and lower Judiciary branches must follow. The STF's justices frequently cite the 58 existing BPs in their decisions, and it is of primary relevance that judicial experts could identify and analyze such citations. To assist in this problem, we propose LegalVis, a web-based visual analytics system designed to support the analysis of legal documents that cite or could potentially cite a BP. We model the problem of identifying potential citations (i.e., non-explicit) as a classification problem. However, a simple score is not enough to explain the results; that is why we use an interpretability machine learning method to explain the reason behind each identified citation. For a compelling visual exploration of documents and BPs, LegalVis comprises three interactive visual components: the first presents an overview of the data showing temporal patterns, the second allows filtering and grouping relevant documents by topic, and the last one shows a document's text aiming to interpret the model's output by pointing out which paragraphs are likely to mention the BP, even if not explicitly specified. We evaluated our identification model and obtained an accuracy of 96%; we also made a quantitative and qualitative analysis of the results. The usefulness and effectiveness of LegalVis were evaluated through two usage scenarios and feedback from six domain experts.",
    "note": "",
    "pub_date": "2022-02-18",
    "url": "https://doi.org/10.1109/TVCG.2022.3152450",
    "authors": [3, 10, 18, 0],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/684392693"
      },
      {
        "name": "Appendix",
        "file": "files/appendix/2023-LegalVis-TVCG.pdf"
      },
      {
        "name": "Video Presentation",
        "link": "https://youtu.be/0qY_NxLSGBk?t=26070"
      }
    ]
  },
  {
    "id": 32,
    "title": "How Do Curricular Design Changes Impact Computer Science Programs?: A Case Study at San Pablo Catholic University in Peru",
    "venue_id": 25,
    "venue": "EducSci",
    "web_name": "CurricularCS",
    "year": 2022,
    "bibtext": "2022-CurricularCS",
    "pdf": "files/papers/2022-CurricularCS-EducSci.pdf",
    "thumbnail": "images/thumbs/2022-CurricularCS.png",
    "figure": "images/figures/2022-CurricularCS.png",
    "caption": "Correlation matrices according to Changed_CD",
    "start_page": "",
    "end_page": "",
    "volume": 12,
    "issue": 4,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Computer science is a dynamic field of study that requires constant review and updating of the curricular designs in academic programs-in general, measuring the impact of plan changes has been little explored in the literature. In most cases, it focuses only on structuring its curricula, leaving aside several factors associated with important events or facts such as student dropout, retention, and inclusion. However, these features provide academic institutions with many opportunities to understand student performance and propose more effective preventive/corrective actions to avoid dropouts. This work focuses on the curricular changes' influence on student gender imbalance, socioeconomic provenance, and dropout. Specifically, we employ three different approaches for our analysis: (i) a longitudinal study of four curricula from informatics engineering to computer science transition at San Pablo Catholic University, (ii) an exploratory analysis for identifying essential features that determines the events mentioned above, and (iii) a survival analysis to estimate the probability that a student will stay (not dropout) before graduate, and calculate the average permanence time per curricula. Our analysis shows that the female student rates decreased, student rates from lower socioeconomic provenance increased, and the dropout rates were reduced with updates towards an internationally standardized curriculum. This is even strongly evidenced when the program changes its name. Finally, the set of techniques employed in this work composes a statistical mechanism that can be replicated/adapted to any other program in computer science aiming to extract valuable insights to support the decision-making process in educational institutions.",
    "note": "",
    "pub_date": "2022-03-28",
    "url": "",
    "authors": [83, 12, 84, 85, 0, 17]
  },
  {
    "id": 33,
    "title": "Combining Clutter Reduction Methods for Temporal Network Visualization",
    "venue_id": 26,
    "venue": "SAC",
    "web_name": "ClutterMethods",
    "year": 2022,
    "bibtext": "2022-ClutterMethods",
    "pdf": "files/papers/2022-ClutterMethods-SAC.pdf",
    "thumbnail": "images/thumbs/2022-ClutterMethods.png",
    "figure": "images/figures/2022-ClutterMethods.png",
    "caption": "",
    "start_page": 1748,
    "end_page": 1755,
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Temporal network visualization is a powerful tool that assists users in understanding network structure and dynamics. One of the most popular visual representations in this context is the Massive Sequence View (MSV), a timeline-based layout that allows the identification of patterns, anomalies, and other structures from global to local scales. MSV may suffer from visual clutter when applied to real-world networks due to the large number of nodes, edges, and/or timestamps. To enhance the analysis, several clutter reduction methods have been proposed in the literature. No study, however, has evaluated different strategies that combine methods with respect to their effectiveness in reducing visual clutter while highlighting meaningful patterns. In this paper, we combine node ordering, edge sampling, and timeslicing methods to analyze how these combinations impact layout readability and pattern identification. We consider recent applications of MSV in the context of infection dynamics to study the effect of different combinations in the visualization layout. Through two case studies with real-world networks, we demonstrate the superiority of combining at least two high-quality methods in relation to the use of a single method. We also show that edge sampling should be used as a complementary strategy, always associated with a high-performance node ordering.",
    "note": "",
    "pub_date": "2022-05-06",
    "url": "https://doi.org/10.1145/3477314.3507018",
    "authors": [10, 23, 24, 87, 88]
  },
  {
    "id": 34,
    "title": "ClinicalPath: A Visualization Tool to Improve the Evaluation of Electronic Health Records in Clinical Decision-Making",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "ClinicalPath",
    "year": 2022,
    "bibtext": "2022-ClinicalPath",
    "pdf": "files/papers/2022-ClinicalPath-TVCG.pdf",
    "thumbnail": "images/thumbs/2022-ClinicalPath.png",
    "figure": "images/figures/2022-ClinicalPath.png",
    "caption": "ClinicalPath, a visualization tool for users to track a patient’s clinical path through a series of tests and data, which can aid in treatments and diagnoses",
    "start_page": 4031,
    "end_page": 4046,
    "volume": 29,
    "issue": 10,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Physicians work at a very tight schedule and need decision-making support tools to help on improving and doing their work in a timely and dependable manner. Examining piles of sheets with test results and using systems with little visualization support to provide diagnostics is daunting, but that is still the usual way for the physicians' daily procedure, especially in developing countries. Electronic Health Records systems have been designed to keep the patients' history and reduce the time spent analyzing the patient's data. However, better tools to support decision-making are still needed. In this paper, we propose ClinicalPath, a visualization tool for users to track a patient's clinical path through a series of tests and data, which can aid in treatments and diagnoses. Our proposal is focused on patient's data analysis, presenting the test results and clinical history longitudinally. Both the visualization design and the system functionality were developed in close collaboration with experts in the medical domain to ensure a right fit of the technical solutions and the real needs of the professionals. We validated the proposed visualization based on case studies and user assessments through tasks based on the physician's daily activities. Our results show that our proposed system improves the physicians' experience in decision-making tasks, made with more confidence and better usage of the physicians' time, allowing them to take other needed care for the patients.",
    "note": "",
    "pub_date": "2022-05-19",
    "url": "https://doi.org/10.1109/TVCG.2022.3175626",
    "authors": [23, 97, 10, 98, 99, 0, 100, 25],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/718018648"
      },
      {
        "name": "Appendix",
        "file": "files/appendix/2022-ClinicalPath-TVCG.pdf"
      }
    ]
  },
  {
    "id": 35,
    "title": "SDA-Vis: A Visualization System for Student Dropout Analysis Based on Counterfactual Exploration",
    "venue_id": 27,
    "venue": "ApplSci",
    "web_name": "SDAVis",
    "year": 2022,
    "bibtext": "2022-SDAVis",
    "pdf": "files/papers/2022-SDAVis-ApplSci.pdf",
    "thumbnail": "images/thumbs/2022-SDAVis.png",
    "figure": "images/figures/2022-SDAVis.png",
    "caption": "SDA-Vis system: a set of linked visual resources enabling the exploration of dropout students' information and their counterfactual explanations.",
    "start_page": "",
    "end_page": "",
    "volume": 12,
    "issue": 12,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "High and persistent dropout rates represent one of the biggest challenges for improving the efficiency of the educational system, particularly in underdeveloped countries. A range of features influence college dropouts, with some belonging to the educational field and others to non-educational fields. Understanding the interplay of these variables to identify a student as a potential dropout could help decision makers interpret the situation and decide what they should do next to reduce student dropout rates based on corrective actions. This paper presents SDA-Vis, a visualization system that supports counterfactual explanations for student dropout dynamics, considering various academic, social, and economic variables. In contrast to conventional systems, our approach provides information about feature-perturbed versions of a student using counterfactual explanations. SDA-Vis comprises a set of linked views that allow users to identify variables alteration to chance predefined students situations. This involves perturbing the variables of a dropout student to achieve synthetic non-dropout students. SDA-Vis has been developed under the guidance and supervision of domain experts, in line with some analytical objectives. We demonstrate the usefulness of SDA-Vis through case studies run in collaboration with domain experts, using a real data set from a Latin American university. The analysis reveals the effectiveness of SDA-Vis in identifying students at risk of dropping out and proposes corrective actions, even for particular cases that have not been shown to be at risk with the traditional tools that experts use.",
    "note": "",
    "pub_date": "2022-06-07",
    "url": "https://www.mdpi.com/2076-3417/12/12/5785",
    "authors": [12, 83, 85, 0, 17],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/718021442"
      }
    ]
  },
  {
    "id": 36,
    "title": "Analyzing the Equity of the Brazilian National High School Exam by Validating the Item Response Theory's Invariance",
    "venue_id": 28,
    "venue": "EDM",
    "web_name": "AnalyzingENEM",
    "year": 2022,
    "bibtext": "2022-AnalyzingENEM",
    "pdf": "files/papers/2022-AnalyzingENEM-EDM.pdf",
    "thumbnail": "images/thumbs/2022-AnalyzingENEM.png",
    "figure": "images/figures/2022-AnalyzingENEM.png",
    "caption": "Heatmap of the Area discrepancy based on the Observed ICC. The color of each square indicates the value of Area discrepancy and the symbol indicates the group with the highest area. As the importance of the indicated grows with the discrepancy, the symbols' visibility also grows with the color.",
    "start_page": 583,
    "end_page": 587,
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Several studies adopt different approaches to examining how economic, racial, and gender circumstances influence student performance in large-scale entrance exams, such as the National High School Exam (ENEM). Using a methodology based on Item Response Theory, ENEM's exam attempts to assess, for each item (question), the curve (function) that relates the participants' abilities to their probabilities of correctly answering the item, which is assumed to hold whichever subgroup, a fundamental premise of IRT called invariance. This work analyzes whether the ENEM 2019 test presented similar curves for subpopulations defined by gender, race, and income, regardless of the participant's actual abilities. Our approach is to analyze the properties of the observed curve for each group and then perform a nonparametric ranking test to compare the equity of each item (question) for each analyzed characteristic. We found that the ”Languages and Codes” questions consistently favored male, white, and high-income participants. At the same time, the other three sets of questions (Mathematics, Natural Sciences, and Human Sciences) were considerably more egalitarian.",
    "note": "",
    "pub_date": "2022-07-24",
    "url": "https://doi.org/10.5281/zenodo.6852946",
    "authors": [5, 8, 0],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/735518962"
      },
      {
        "name": "Poster",
        "file": "files/poster/2022-AnalyzingENEM-EDM.pdf"
      }
    ]
  },
  {
    "id": 37,
    "title": "LargeNetVis: Visual Exploration of Large Temporal Networks Based on Community Taxonomies",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "LargeNetVis",
    "year": 2023,
    "bibtext": "2023-LargeNetVis",
    "pdf": "files/papers/2023-LargeNetVis-TVCG.pdf",
    "thumbnail": "images/thumbs/2023-LargeNetVis.png",
    "figure": "images/figures/2023-LargeNetVis.png",
    "caption": "",
    "start_page": 203,
    "end_page": 213,
    "volume": 29,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Temporal (or time-evolving) networks are commonly used to model complex systems and the evolution of their components throughout time. Although these networks can be analyzed by different means, visual analytics stands out as an effective way for a pre-analysis before doing quantitative/statistical analyses to identify patterns, anomalies, and other behaviors in the data, thus leading to new insights and better decision-making. However, the large number of nodes, edges, and/or timestamps in many real-world networks may lead to polluted layouts that make the analysis inefficient or even infeasible. In this paper, we propose LargeNetVis, a web-based visual analytics system designed to assist in analyzing small and large temporal networks. It successfully achieves this goal by leveraging three taxonomies focused on network communities to guide the visual exploration process. The system is composed of four interactive visual components: the first (Taxonomy Matrix) presents a summary of the network characteristics, the second (Global View) gives an overview of the network evolution, the third (a node-link diagram) enables community- and node-level structural analysis, and the fourth (a Temporal Activity Map – TAM) shows the community- and node-level activity under a temporal perspective.",
    "note": "",
    "pub_date": "2023-01-15",
    "url": "10.1109/TVCG.2022.3209477",
    "authors": [23, 10, 102, 24, 25, 0],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/738097881"
      },
      {
        "name": "Appendix",
        "file": "files/appendix/2022-LargeNetVis-TVCG.pdf"
      },
      {
        "name": "Demo",
        "link": "http://visualdslab.com/largenetvis"
      },
      {
        "name": "Video Presentation",
        "link": "https://youtu.be/L523gBLIM5c?t=2328"
      }
    ]
  },
  {
    "id": 38,
    "title": "Mining Pareto-Optimal Counterfactual Antecedents with a Branch-And-Bound Model-Agnostic Algorithm",
    "venue_id": 30,
    "venue": "DMKD",
    "web_name": "MAPOCAM",
    "year": 2022,
    "bibtext": "2022-MAPOCAM",
    "pdf": "files/papers/2022-MAPOCAM-DMKD.pdf",
    "thumbnail": "images/thumbs/2022-MAPOCAM.png",
    "figure": "images/figures/2022-MAPOCAM.png",
    "caption": "Enumeration for Logistic Regression of counterfactual antecedents with Pareto-optimal values when each feature is considered as an objective function. Orig column is the original sample and the columns C1 to C28 are counterfactual antecedents.",
    "start_page": "",
    "end_page": "",
    "volume": 36,
    "issue": 6,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Mining counterfactual antecedents became a valuable tool to discover knowledge and explain machine learning models. It consists of generating synthetic samples from an original sample to achieve the desired outcome in a machine learning model, thus helping to understand the prediction. An insightful methodology would explore a broader set of counterfactual antecedents to reveal multiple possibilities while operating on any classifier. Therefore, we create a tree-based search that requires monotonicity from the objective functions (a.k.a. cost functions); it allows pruning branches that will not improve the objective functions. Since monotonicity is only required for the objective function, this method can be used for any family of classifiers (e.g., linear models, neural networks, and decision trees). However, additional classifier properties speed up the tree search when it foresees branches that will not result in feasible actions. Moreover, the proposed optimization generates a diverse set of Pareto-optimal counterfactual antecedents by relying on multi-objective concepts. The results show an algorithm with working guarantees that enumerates a wide range of counterfactual antecedents. It helps the decision-maker understand the machine learning decision and finds alternatives to achieve the desired outcome. The user can inspect these multiple counterfactual antecedents to find the most suitable one and better understand the prediction.",
    "note": "",
    "pub_date": "2022-12-16",
    "url": "https://doi.org/10.1007/s10618-022-00906-4",
    "authors": [8, 18, 0],
    "links": [
      {
        "name": "Journal",
        "link": "https://link.springer.com/article/10.1007/s10618-022-00906-4"
      }
    ]
  },
  {
    "id": 39,
    "title": "WSAM: Visual Explanations from Style Augmentation as Adversarial Attacker and their Influence in Image Classification",
    "venue_id": 23,
    "venue": "VISAPP",
    "web_name": "WSAM",
    "year": 2023,
    "bibtext": "2023-WSAM",
    "pdf": "files/papers/2023-WSAM-VISAPP.pdf",
    "thumbnail": "images/thumbs/2023-WSAM.png",
    "figure": "images/figures/2023-WSAM.png",
    "caption": "Comparison of SAM results obtained from WideResNet-101 evaluation using N/A, Trad, SA, and Trad+SA tested on the same image and style but varying the style intensity alpha as input.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Currently, style augmentation is capturing attention due to convolutional neural networks (CNN) being strongly biased toward recognizing textures rather than shapes. Most existing styling methods either perform a low-fidelity style transfer or a weak style representation in the embedding vector. This paper outlines a style augmentation algorithm using stochastic-based sampling with noise addition for randomization improvement on a general linear transformation for style transfer. With our augmentation strategy, all models not only present incredible robustness against image stylizing but also outperform all previous methods and surpass the state-of-the-art performance for the STL-10 dataset. In addition, we present an analysis of the model interpretations under different style variations. At the same time, we compare comprehensive experiments demonstrating the performance when applied to deep neural architectures in training settings.",
    "note": "",
    "pub_date": "2023-02-21",
    "url": "",
    "authors": [4, 104, 0]
  },
  {
    "id": 40,
    "title": "Enforcing Fairness using Ensemble of Diverse Pareto-Optimal Models",
    "venue_id": 30,
    "venue": "DMKD",
    "web_name": "EnforcingFairness",
    "year": 2023,
    "bibtext": "2023-EnforcingFairness",
    "pdf": "files/papers/2023-EnforcingFairness-DMKD.pdf",
    "thumbnail": "images/thumbs/2023-EnforcingFairness.png",
    "figure": "images/figures/2023-EnforcingFairness.png",
    "caption": "Visual description of the proposed methodology",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "One of the main challenges of machine learning is to ensure that its applications do not generate or propagate unfair discrimination based on sensitive characteristics such as gender, race, and ethnicity. Research in this area typically limits models to a level of discrimination quantified by an equity metric (usually the “benefit” discrepancy between privileged and non-privileged groups). However, when models reduce bias, they may also reduce their performance (e.g., accuracy, F1 score). Therefore, we have to optimize contradictory metrics (performance and fairness) at the same time. This problem is well characterized as a multi-objective optimization (MOO) problem. In this study, we use MOO methods to minimize the difference between groups, maximize the benefits for each group, and preserve performance. We search for the best trade-off models in binary classification problems and aggregate them using ensemble filtering and voting procedures. The aggregation of models with different levels of benefits for each group improves robustness regarding performance and fairness. We compared our approach with other known methodologies, using logistic regression as a benchmark for comparison. The proposed methods obtained interesting results: (i) multi-objective training found models that are similar to or better than the adversarial methods and are more diverse in terms of fairness and accuracy metrics, (ii) multi-objective selection was able to improve the balance between fairness and accuracy compared to selection with a single metric, and (iii) the final predictor found models with higher fairness without sacrificing much accuracy.",
    "note": "",
    "pub_date": "2023-02-14",
    "url": "https://link.springer.com/article/10.1007/s10618-023-00922-y",
    "authors": [5, 8, 0],
    "links": [
      {
        "name": "Journal",
        "link": "https://link.springer.com/article/10.1007/s10618-023-00922-y"
      }
    ]
  },
  {
    "id": 41,
    "title": "MoReVis: A Visual Summary for Spatiotemporal Moving Regions",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "MoReVis",
    "year": 2023,
    "bibtext": "2023-MoReVis",
    "pdf": "files/papers/2023-MoReVis-TVCG.pdf",
    "thumbnail": "images/thumbs/2023-MoReVis.png",
    "figure": "images/figures/2023-MoReVis.png",
    "caption": "",
    "start_page": 1927,
    "end_page": 1941,
    "volume": 30,
    "issue": 4,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Spatial and temporal interactions are central and fundamental in many activities in our world. A common problem faced when visualizing this type of data is how to provide an overview that helps users navigate efficiently. Traditional approaches use coordinated views or 3D metaphors like the Space-time cube to tackle this problem. However, they suffer from overplotting and often lack spatial context, hindering data exploration. More recent techniques, such as MotionRugs, propose compact temporal summaries based on 1D projection. While powerful, these techniques do not support the situation for which the spatial extent of the objects and their intersections is relevant, such as the analysis of surveillance videos or tracking weather storms. In this paper, we propose MoReVis, a visual overview of spatiotemporal data that considers the objects' spatial extent and strives to show spatial interactions among these objects by displaying spatial intersections. Like previous techniques, our method involves projecting the spatial coordinates to 1D to produce compact summaries. However, our solution's core consists of performing a layout optimization step that sets the size and positions of the visual marks on the summary to resemble the actual values on the original space. We also provide multiple interactive mechanisms to make interpreting the results more straightforward for the user. We perform an extensive experimental evaluation and usage scenarios. Moreover, we evaluated the usefulness of MoReVis in a study with 9 participants. The results point out the effectiveness and suitability of our method in representing different datasets compared to traditional techniques.",
    "note": "",
    "pub_date": "2023-06-01",
    "url": "",
    "authors": [1, 16, 0],
    "links": [
      {
        "name": "Code",
        "link": "https://github.com/visual-ds/morevis"
      },
      {
        "name": "Video",
        "link": "https://vimeo.com/801624188"
      }
    ]
  },
  {
    "id": 42,
    "title": "Distill n’ Explain: Explaining Graph Neural Networks Using Simple Surrogates",
    "venue_id": 31,
    "venue": "AISTATS",
    "web_name": "DnX",
    "year": 2023,
    "bibtext": "2023-DnX",
    "pdf": "files/papers/2023-DnX-AISTATS.pdf",
    "thumbnail": "images/thumbs/2023-DnX.png",
    "figure": "images/figures/2023-DnX.jpg",
    "caption": "How to explain the prediction of a GNN node classification? Distill n' Explain is a novel GNN explainer that highlights important nodes that influenced such a prediction. It first distills the GNN and explains it afterward.",
    "start_page": 6199,
    "end_page": 6214,
    "volume": 206,
    "issue": 1,
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n’ Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faithfulness of explanations.",
    "note": "",
    "pub_date": "2023-04-11",
    "url": "https://proceedings.mlr.press/v206/pereira23a.html",
    "authors": [112, 113, 3, 114, 115],
    "links": [
      {
        "name": "Poster",
        "file": "files/poster/2023-DnX-AISTATS.pdf"
      },
      {
        "name": "Code",
        "link": "https://github.com/tamararruda/DnX"
      },
      {
        "name": "Video",
        "link": "https://www.youtube.com/watch?v=DsTpJfjz6BQ"
      }
    ]
  },
  {
    "id": 43,
    "title": "Granularity at Scale: Estimating Neighborhood Socioeconomic Indicators from High-Resolution Orthographic Imagery and Hybrid Learning",
    "venue_id": 32,
    "venue": "JSTARS",
    "web_name": "ENSI",
    "year": 2024,
    "bibtext": "2024-ENSI",
    "pdf": "files/papers/2024-ENSI-JSTARS.pdf",
    "thumbnail": "images/thumbs/2024-ENSI.png",
    "figure": "images/figures/2024-ENSI.png",
    "caption": "Overall steps of the semi-supervised methodology. First, an unsupervised clustering algorithm is used to cluster small patches of neighborhoods from aerial imagery. The clustering uses ResNet50 as a feature extractor and an autoencoder. The second step is supervised regression on the target variables using the distribution of clusters composed of neighborhood patches.",
    "start_page": 5668,
    "end_page": 5679,
    "volume": 17,
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Many areas of the world are without basic information on the socioeconomic well-being of the residing population due to limitations in existing data collection methods. Overhead images obtained remotely, such as from satellite or aircraft, can help serve as windows into the state of life on the ground and help 'fill in the gaps' where community information is sparse, with estimates at smaller geographic scales requiring higher resolution sensors. Concurrent with improved sensor resolutions, recent advancements in machine learning and computer vision have made it possible to quickly extract features from and detect patterns in image data, in the process correlating these features with other information. In this work, we explore how well two approaches—a supervised convolutional neural network and semi-supervised clustering based on bag-of-visual-words—estimate population density, median household income, and educational attainment of individual neighborhoods from publicly available high-resolution imagery of cities throughout the United States. Results and analyses indicate that features extracted from the imagery can accurately estimate the density (R^2 up to 0.81) of neighborhoods, with the supervised approach able to explain about half the variation in a population's income and education. In addition to the presented approaches serving as a basis for further geographic generalization, the novel semi-supervised approach provides a foundation for future work seeking to estimate fine-scale information from aerial imagery without the need for label data.",
    "note": "",
    "pub_date": "2024-02-21",
    "url": "10.1109/JSTARS.2024.3368018",
    "authors": [118, 1, 119, 120, 121, 122, 0, 15]
  },
  {
    "id": 44,
    "title": "Exploring the Trade-off Between Model Performance and Explanation Plausibility of Text Classifiers Using Human Rationales",
    "venue_id": 33,
    "venue": "NAACL Findings",
    "web_name": "PlausibleNLPExplanations",
    "year": 2024,
    "bibtext": "2024-PlausibleNLPExplanations",
    "pdf": "files/papers/2024-PlausibleNLPExplanations-NAACL Findings.pdf",
    "thumbnail": "images/thumbs/2024-PlausibleNLPExplanations.png",
    "figure": "images/figures/2024-PlausibleNLPExplanations.png",
    "caption": "Examples of local saliency post-hoc explanations from a hypothetical text classifier for a positive movie review. Explanation (a) is more plausible than (b). Green means a positive contribution to the model’s prediction, and red is negative.",
    "start_page": 4190,
    "end_page": 4216,
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Saliency post-hoc explainability methods are important tools for understanding increasingly complex NLP models. While these methods can reflect the model's reasoning, they may not align with human intuition, making the explanations not plausible. In this work, we present a methodology for incorporating rationales, which are text annotations explaining human decisions, into text classification models. This incorporation enhances the plausibility of post-hoc explanations while preserving their faithfulness. Our approach is agnostic to model architectures and explainability methods. We introduce the rationales during model training by augmenting the standard cross-entropy loss with a novel loss function inspired by contrastive learning. By leveraging a multi-objective optimization algorithm, we explore the trade-off between the two loss functions and generate a Pareto-optimal frontier of models that balance performance and plausibility. Through extensive experiments involving diverse models, datasets, and explainability methods, we demonstrate that our approach significantly enhances the quality of model explanations without causing substantial (sometimes negligible) degradation in the original model's performance.",
    "note": "",
    "pub_date": "2024-06-16",
    "url": "https://aclanthology.org/2024.findings-naacl.262/",
    "authors": [3, 8, 0],
    "links": [
      {
        "name": "Code",
        "link": "https://github.com/visual-ds/plausible-nlp-explanations"
      }
    ]
  },
  {
    "id": 45,
    "title": "Empirical analysis of Binding Precedent efficiency in the Brazilian Supreme Court via Similar Case Retrieval (in-press)",
    "venue_id": 11,
    "venue": "arXiv",
    "web_name": "MLSV",
    "year": 2024,
    "bibtext": "2024-MLSV",
    "pdf": "files/papers/2024-MLSV-arXiv.pdf",
    "thumbnail": "images/thumbs/2024-MLSV.png",
    "figure": "images/figures/2024-MLSV.png",
    "caption": "Schematic overview of the article. To understand the dynamics behind the use of a precedent, we train the models on an initial set of labeled documents, then apply these models to a larger set of data, and represent the results as a time series.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Binding precedents (Súmulas Vinculantes) constitute a juridical instrument unique to the Brazilian legal system and whose objectives include the protection of the Federal Supreme Court against repetitive demands. Studies of the effectiveness of these instruments in decreasing the Court's exposure to similar cases, however, indicate that they tend to fail in such a direction, with some of the binding precedents seemingly creating new demands. We empirically assess the legal impact of five binding precedents, 11, 14, 17, 26 and 37, at the highest court level through their effects on the legal subjects they address. This analysis is only possible through the comparison of the Court's ruling about the precedents' themes before they are created, which means that these decisions should be detected through techniques of Similar Case Retrieval. The contributions of this article are therefore twofold: on the mathematical side, we compare the uses of different methods of Natural Language Processing -- TF-IDF, LSTM, BERT, and regex -- for Similar Case Retrieval, whereas on the legal side, we contrast the inefficiency of these binding precedents with a set of hypotheses that may justify their repeated usage. We observe that the deep learning models performed significantly worse in the specific Similar Case Retrieval task and that the reasons for binding precedents to fail in responding to repetitive demand are heterogeneous and case-dependent, making it impossible to single out a specific cause.",
    "note": "",
    "pub_date": "2024-09-07",
    "url": "https://arxiv.org/abs/2407.07004",
    "authors": [13, 14, 3, 125, 10, 0]
  },
  {
    "id": 46,
    "title": "FishBiasLens: Integrating Large Language Models and Visual Analytics for Bias Detection",
    "venue_id": 34,
    "venue": "VAST Challenge",
    "web_name": "FishBiasLens",
    "year": 2024,
    "bibtext": "2024-FishBiasLens",
    "pdf": "files/papers/2024-FishBiasLens-VAST Challenge.pdf",
    "thumbnail": "images/thumbs/2024-FishBiasLens.png",
    "figure": "images/figures/2024-FishBiasLens.png",
    "caption": "Overview of our visualization system: The panels (A–C) display companies and temporal journal reports—(A) Company Graph, (B) Journal Bias Timeline, (C) Journal Bias Breakdown.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Identifying unreliable sources is crucial for preventing misinformation and making informed decisions. CatchNet, the Oceanus Knowledge Graph, contains biased perspectives that threaten its credibility. We use Large Language Models (LLMs) and interactive visualization systems to identify these biases. By analyzing police reports and using GPT-3.5 to extract information from articles, we establish the ground truth for our analysis. Our visual analytics system detects anomalies, revealing unreliable news sources such as The News Buoy and biased analysts such as Harvey Janus and Junior Shurdlu",
    "note": "",
    "pub_date": "2024-10-13",
    "url": "",
    "authors": [108, 4, 103, 110, 0],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/1018871681"
      }
    ]
  },
  {
    "id": 47,
    "title": "Tracking Overfishing: Visual Analytics of Suspicious Behaviors in Commercial Fishing Vessels",
    "venue_id": 34,
    "venue": "VAST Challenge",
    "web_name": "TrackingOverfishing",
    "year": 2024,
    "bibtext": "2024-TrackingOverfishing",
    "pdf": "files/papers/2024-TrackingOverfishing-VAST Challenge.pdf",
    "thumbnail": "images/thumbs/2024-TrackingOverfishing.png",
    "figure": "images/figures/2024-TrackingOverfishing.png",
    "caption": "Overview of the implemented visualization system. (a) Oceanus map view highlighting vessels’ transit locations; (b) Trajectory views: (b.1) Visualization options and list of similar vessels, (b.2) Trajectory of the selected vessel, (b.3) Trajectory of the fixed vessel; (c) Bar chart of total dwell time by location for selected and fixed vessels; (d) Time chart for the selected vessel.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "The exposure of illegal fishing by SouthSeafood Express Corp highlights the urgent need for better tools to monitor commercial fishing in Oceanus. In response, we develop an interactive visualization tool for the VAST Challenge’s Mini-Challenge 2. Our system analyzes the CatchNet knowledge graph, combining vessel tracking and port records from FishEye International, a non-profit dedicated to combating illegal fishing. The tool links vessels to probable cargos, identifies seasonal trends, and detects anomalies in port records. Detects suspicious activity of vessels, offering actionable insights to aid investigations and prevent future illegal fishing.",
    "note": "",
    "pub_date": "2024-10-13",
    "url": "",
    "authors": [103, 110, 108, 4, 0],
    "links": [
      {
        "name": "Video",
        "link": "https://vimeo.com/1026637544"
      }
    ]
  },
  {
    "id": 48,
    "title": "What Makes a Place Feel Safe? Analyzing Street View Images to Identify Relevant Visual Elements",
    "venue_id": 22,
    "venue": "WI-IAT",
    "web_name": "StreetView",
    "year": 2024,
    "bibtext": "2024-StreetView",
    "pdf": "files/papers/2024-StreetView-WI-IAT.pdf",
    "thumbnail": "images/thumbs/2024-StreetView.png",
    "figure": "images/figures/2024-StreetView.png",
    "caption": "The proposed Urbanformer combines the OneFormer vectorized output with a modified ViT probability vector output to predict street human perception between safe and unsafe.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Over the past four decades, urban perception has become a vital area of research that intersects multiple fields, such as criminology, psychology, and urban planning. This interdisciplinary approach seeks to understand and interpret how people perceive urban environments and how these perceptions shape their behavior. The surge in data collection methods, driven by modern web technologies and services, has enabled researchers to apply techniques from various domains to better quantify and analyze urban perception. In this study, we present the UrbanFormer, a vision transformer-based model, to address the task of urban perception analysis, leveraging the widely-used Place Pulse 2.0 dataset. Our focus is on the safety category, a key issue in urban perception, while employing vision transformer and explainability methods to provide insights into the decision-making process behind perception analysis.",
    "note": "",
    "pub_date": "2024-12-12",
    "url": "",
    "authors": [4, 105, 0]
  },
  {
    "id": 49,
    "title": "Assessing timber trade networks and supply chains in Brazil",
    "venue_id": 35,
    "venue": "NATSUSTAIN",
    "web_name": "TimberChain",
    "year": 2025,
    "bibtext": "2025-TimberChain",
    "pdf": "files/papers/2025-TimberChain-NATSUSTAIN.pdf",
    "thumbnail": "images/thumbs/2025-TimberChain.png",
    "figure": "images/figures/2025-TimberChain.png",
    "caption": "The five largest connected components for the Ipe’s TTN.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Forest degradation in the Brazilian Amazon is driven by factors such as fire, mining, and illegal logging. The Brazilian government has implemented control mechanisms to combat illegal timber extraction that have positively impacted deforestation rates. Under these regulations, all wood products, from raw logs to processed lumber, must be registered in control systems before transportation. This allows analysis of wood products transported between companies over time. However, the existence of three partially integrated control systems complicates a full analysis of the timber market. This study integrates data from these systems to create Timber Trade Networks (TTNs), which help identify companies or groups operating outside expected standards. We also propose a method to trace probable supply chains of timber companies, addressing long-standing government concerns about timber traceability. Among the results, we show that certain TTNs have components that operate without connections with licensed forests, suggesting that unregistered timber is input into those components, which is illegal. Additionally, we illustrate how supply chain analysis can significantly enhance customer confidence in the legality of purchased timber products.",
    "note": "",
    "pub_date": "2025-01-06",
    "url": "https://www.nature.com/articles/s41893-024-01491-8",
    "authors": [18, 129, 130, 4, 131, 132, 133, 134, 0],
    "links": [
      {
        "name": "Journal",
        "link": "https://www.nature.com/articles/s41893-024-01491-8"
      }
    ]
  },
  {
    "id": 50,
    "title": "ZigzagNetVis: Suggesting temporal resolutions",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "ZigzagNetVis",
    "year": 2025,
    "bibtext": "2025-ZigzagNetVis",
    "pdf": "files/papers/2025-ZigzagNetVis-TVCG.pdf",
    "thumbnail": "images/thumbs/2025-ZigzagNetVis.png",
    "figure": "images/figures/2025-ZigzagNetVis.png",
    "caption": "ZigzagNetVis system prototype, an interactive and web-based system with linked views designed to assist the analysis of temporal graphs by highlighting connected components’ structure and evolution. (A) Colored barcode with bottom-based ordering that highlights the longest connected component in the graph — note that (i), (ii), and (iii) represent time intervals with few connected components compared to others. (B) Timestamp markers indicating the three timestamps being depicted by (C-E) the three node-link diagrams. (F) Tooltip showing extra information. (G) Users can select groups of nodes by label or by connected component. (H) Users can choose between two available component positioning strategies.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Temporal graphs are commonly used to represent complex systems and track the evolution of their constituents over time. Visualizing these graphs is crucial as it allows one to quickly identify anomalies, trends, patterns, and other properties that facilitate better decision-making. In this context, selecting an appropriate temporal resolution is essential for constructing and visually analyzing the layout. The choice of resolution is particularly important, especially when dealing with temporally sparse graphs. In such cases, changing the temporal resolution by grouping events (i.e., edges) from consecutive timestamps — a technique known as timeslicing — can aid in the analysis and reveal patterns that might not be discernible otherwise. However, selecting an appropriate temporal resolution is a challenging task. In this paper, we propose ZigzagNetVis, a methodology that suggests temporal resolutions potentially relevant for analyzing a given graph, i.e., resolutions that lead to substantial topological changes in the graph structure. ZigzagNetVis achieves this by leveraging zigzag persistent homology, a well-established technique from Topological Data Analysis (TDA). To improve visual graph analysis, ZigzagNetVis incorporates the colored barcode, a novel timeline-based visualization inspired by persistence barcodes commonly used in TDA. We also contribute with a web-based system prototype that implements suggestion methodology and visualization tools. Finally, we demonstrate the usefulness and effectiveness of ZigzagNetVis through a usage scenario, a user study with 27 participants, and a detailed quantitative evaluation.",
    "note": "",
    "pub_date": "2025-01-17",
    "url": "https://ieeexplore.ieee.org/abstract/document/10844578",
    "authors": [13, 10, 23, 25, 0]
  },
  {
    "id": 51,
    "title": "ZigzagNetVis: Suggesting temporal resolutions 2",
    "venue_id": 3,
    "venue": "TVCG",
    "web_name": "ZigzagNetVis",
    "year": 2025,
    "bibtext": "2025-ZigzagNetVis",
    "pdf": "files/papers/2025-ZigzagNetVis-TVCG.pdf",
    "thumbnail": "images/thumbs/2025-ZigzagNetVis.png",
    "figure": "images/figures/2025-ZigzagNetVis.png",
    "caption": "ZigzagNetVis system prototype, an interactive and web-based system with linked views designed to assist the analysis of temporal graphs by highlighting connected components’ structure and evolution. (A) Colored barcode with bottom-based ordering that highlights the longest connected component in the graph — note that (i), (ii), and (iii) represent time intervals with few connected components compared to others. (B) Timestamp markers indicating the three timestamps being depicted by (C-E) the three node-link diagrams. (F) Tooltip showing extra information. (G) Users can select groups of nodes by label or by connected component. (H) Users can choose between two available component positioning strategies.",
    "start_page": "",
    "end_page": "",
    "volume": "",
    "issue": "",
    "editors": "0",
    "publisher": "0",
    "location": "0",
    "abstract": "Temporal graphs are commonly used to represent complex systems and track the evolution of their constituents over time. Visualizing these graphs is crucial as it allows one to quickly identify anomalies, trends, patterns, and other properties that facilitate better decision-making. In this context, selecting an appropriate temporal resolution is essential for constructing and visually analyzing the layout. The choice of resolution is particularly important, especially when dealing with temporally sparse graphs. In such cases, changing the temporal resolution by grouping events (i.e., edges) from consecutive timestamps — a technique known as timeslicing — can aid in the analysis and reveal patterns that might not be discernible otherwise. However, selecting an appropriate temporal resolution is a challenging task. In this paper, we propose ZigzagNetVis, a methodology that suggests temporal resolutions potentially relevant for analyzing a given graph, i.e., resolutions that lead to substantial topological changes in the graph structure. ZigzagNetVis achieves this by leveraging zigzag persistent homology, a well-established technique from Topological Data Analysis (TDA). To improve visual graph analysis, ZigzagNetVis incorporates the colored barcode, a novel timeline-based visualization inspired by persistence barcodes commonly used in TDA. We also contribute with a web-based system prototype that implements suggestion methodology and visualization tools. Finally, we demonstrate the usefulness and effectiveness of ZigzagNetVis through a usage scenario, a user study with 27 participants, and a detailed quantitative evaluation.",
    "note": "",
    "pub_date": "2025-01-17",
    "url": "https://ieeexplore.ieee.org/abstract/document/10844578",
    "authors": [13, 10, 23, 25]
  }
]
