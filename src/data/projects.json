[
  {
    "id": 1,
    "title": "Urban Mobility Analysis",
    "web_name": "UrbanMobilityAnalysis",
    "figure": "/projects/UrbanMobilityAnalysis.png",
    "abstract": "Urban Mobility is a research project that aims to develop visual systems that help to visualize, analyze, and understand the behavior of urban transport in different cities. This project covers methods of visualization, pattern detection, and functional analysis. This project aims to develop tools that allow visualizing and analyzing large amounts of spatial-temporal data of urban mobility through different visualization techniques, pattern detection, and functional analysis. The current project consists of two main approaches: The first one presents TaxiVis, a system that allows the analysis of the behavior of New York City's taxis through different visual components. The second presents a vector-based model that allows the analysis of traffic dynamics. This model is based on the vehicles' speed and direction, which allows it to detect interesting mobility patterns in New York City.",
    "caption": null,
    "description": "Urban Mobility aims to develop visual systems that help to visualize and analyze",
    "visible": true,
    "type": "c",
    "papers": [6, 8, 10, 29]
  },
  {
    "id": 2,
    "title": "Automatic Chart Interpretation",
    "web_name": "AutomaticChartInterpretation",
    "figure": "/projects/AutomaticChartInterpretation.png",
    "abstract": "Visualizations are commonly used to present quantitative information. They are ubiquitous in scientific articles, textbooks, economic reports, press articles, and web pages. In many cases, these visualizations are the only publicly available representation of the underlying data. When well designed, visualizations leverage human visual processing to convey information efficiently and effectively. But these representations are not intended for machine consumption. It is unfortunate, as centuries of publications (both print and online) represent data visually.\n\nThis project aims to develop computational models for interpreting data-driven diagrams to extract the underlying data, the graphical marks, and mappings that link the data to mark attributes. Moreover, our results can enable a variety of applications. A straightforward application is to use this information to improve search engines by better-incorporating figures. Another application area is restyling or retargeting visualizations; this task is essential as many published charts exhibit poor perceptual design choices that may hamper understanding.",
    "caption": null,
    "description": "Automatic Chart Interpretation aims to develop computational models for interpreting data-driven diagrams",
    "visible": true,
    "type": "c",
    "papers": [14, 15, 16, 30]
  },
  {
    "id": 3,
    "title": "Crime Analytics",
    "web_name": "CrimeAnalytics",
    "figure": "/projects/CrimeAnalytics.png",
    "abstract": "Visual Data Crime is a research project that aims at creating computational systems to help identify, understand, and predict criminality. The goal is to explore data from space-temporal crime occurrences, safety perception, socioeconomic traits, and amenity features to help specialists and decision-makers deal with criminality. Knowing the wide range of analyses on criminal behavior and its relations with other variables, this project relies on jointly using machine learning, visualization systems, and optimization methods. Machine learning is used to automatically find crime patterns. Visualization frameworks to help decision-makers to understand found patterns as well as directly search for those patterns. Optimization methods are used to tune and help explaining learning machines, and to automatically improve the visualization tools.",
    "caption": null,
    "description": "Crime Analytics helps to identify, understand, and predict criminality",
    "visible": true,
    "type": "c",
    "papers": [18, 19, 21, 24, 27, 28]
  },
  {
    "id": 4,
    "title": "Legal Analytics",
    "web_name": "LegalAnalytics",
    "figure": "/projects/LegalAnalytics.png",
    "abstract": "To reduce the number of pending cases and conflicting rulings in the Brazilian Judiciary, the National Congress amended the Constitution, allowing the Brazilian Supreme Court (STF) to create binding precedents (BPs), i.e., a set of understandings that both Executive and lower Judiciary branches must follow. The STF\u2019s justices frequently cite the 58 existing BPs in their decisions, and it is of primary relevance that judicial experts could identify and analyze such citations. This project aims to create computational methodologies to assist lawyers and other experts in analyzing legal documents that cite or that potentially cite BPs. Our primary objective is to identify and explain meaningful patterns, anomalies, shared characteristics and other relevant behaviors that may involve different STF justices, decisions and/or binding precedents.",
    "caption": null,
    "description": "Legal Analytics identifies and explains patterns in the Supreme Court's decisions",
    "visible": true,
    "type": "c",
    "papers": [32]
  },
  {
    "id": 5,
    "title": "LegalVis",
    "web_name": "LegalVis",
    "figure": "/projects/LegalVis.png",
    "abstract": "To reduce the number of pending cases and conflicting rulings in the Brazilian Judiciary, the National Congress amended the Constitution, allowing the Brazilian Supreme Court (STF) to create binding precedents (BPs), i.e., a set of understandings that both Executive and lower Judiciary branches must follow. The STF\u2019s justices frequently cite the 58 existing BPs in their decisions, and it is of primary relevance that judicial experts could identify and analyze such citations. To assist in this problem, we propose LegalVis, a web-based visual analytics system designed to support the analysis of legal documents that cite or could potentially cite a BP. We model the problem of identifying potential citations (i.ie., non-explicit) as a classification problem. However, a simple score is not enough to explain the results; that is why we use an interpretability machine learning method to explain the reason behind each identified citation. For a compelling visual exploration of documents and BPs, LegalVis comprises three interactive visual components: the first presents an overview of the data showing temporal patterns, the second allows filtering and grouping relevant documents by topic, and the last one shows a document\u2019s text aiming to interpret the model\u2019s output by pointing out which paragraphs are likely to mention the BP, even if not explicitly specified.",
    "caption": null,
    "description": "Exploring and Inferring Precedent Citations in Legal Documents",
    "visible": false,
    "type": "s",
    "papers": []
  },
  {
    "id": 6,
    "title": "TDA applied to Legal Documents",
    "web_name": "TDALegalDocuments",
    "figure": "/projects/TDALegalDocuments.png",
    "abstract": "To reduce the number of pending cases and conflicting rulings in the Brazilian Judiciary, the National Congress amended the Constitution, allowing the Brazilian Supreme Court (STF) to create binding precedents (BPs), i.e., a set of understandings that both Executive and lower Judiciary branches must follow. The STF justices frequently cite the 58 existing BPs in their decisions, and it is of primary relevance that judicial experts could identify and analyze such decisions and citations. To assist in this problem, this project aims to create a methodology of analysis that represents STF decisions in a multidimensional vector space and then leverages Topological Data Analysis strategies to analyze such decisions. Our objective is to identify and explain meaningful patterns, anomalies, shared characteristics and other relevant behaviors that may involve different STF justices, decisions and/or binding precedents. Given the date of publication inherent to each decision, a second line of investigation that we take into account in this project is the analysis of the data under a temporal evolution perspective.",
    "caption": null,
    "description": "Short Description",
    "visible": false,
    "type": "s",
    "papers": []
  },
  {
    "id": 7,
    "title": "Algorithmic Fairness",
    "web_name": "AlgorithmicFairness",
    "figure": "/projects/AlgorithmicFairness.png",
    "abstract": "Algorithmic Fairness is a research project that aims at mitigating any form of discrimination that might be created, perpetuated or increased when a computational system is designed -- espetially artificial intelligence systems. This project goal is to cover many aspects in fairness: (1) Identification of applications that might increase or propagate bias against minorities; (2) Design experiments/applications that investigate the fairness of already established machine learning models, particularly on application in Latin America; (3) Proposition of algorithms that are flexible enough to reduce fairness; (4) Create systems that helps experts to select the most appropriate model on each application, balancing fairness and accuracy goals.",
    "caption": null,
    "description": "Algorithmic Fairness aims to mitigate any form of discrimination",
    "visible": true,
    "type": "c",
    "papers": [37, 41]
  },
  {
    "id": 8,
    "title": "Network Visualization",
    "web_name": "NetworkVisualization",
    "figure": "/projects/NetworkVisualization.png",
    "abstract": "Networks represent a useful and widely adopted structure to model systems from distinct areas, such as computer science (e.g., computers linked by communication protocols), biology (e.g., chemical reactions in cells), sociology (e.g., face-to-face interactions), and others. Visual analysis of temporal networks comprises an effective way to understand the network dynamics. It facilitates the identification of patterns, anomalies, and other network properties, thus resulting in fast decision making. The amount of data in real-world networks, however, may result in a layout with high visual clutter, consequently impairing the analysis. All three network dimensions, namely node, edge, and time, play important roles in the layout construction and, consequently, in the visual analysis. This project aims to create network manipulation and visualization strategies to enhance the visual analysis of small and large temporal networks.",
    "caption": null,
    "description": "Network Visualization aims to guide users in the analysis of complex systems",
    "visible": true,
    "type": "c",
    "papers": [22, 34, 38]
  },
  {
    "id": 9,
    "title": "LargeNetVis",
    "web_name": "LargeNetVis",
    "figure": "/projects/LargeNetVis.png",
    "abstract": "Networks represent a useful and widely adopted structure to model systems from distinct areas, such as computer science (e.g., computers linked by communication protocols), biology (e.g., chemical reactions in cells), sociology (e.g., face-to-face interactions), and others. Visual analysis of temporal networks comprises an effective way to understand the network dynamics. It facilitates the identification of patterns, anomalies, and other network properties, thus resulting in fast decision making. The amount of data in real-world networks, however, may result in a layout with high visual clutter, consequently impairing the analysis.  This project aims to create a visualization methodology along with a web-based visual analytic system that will allow users to explore large temporal networks (in terms of the number of elements, connections, and/or timestamps). The methodology we propose leverages the network community structure, i.e., information of groups of elements highly connected over time, to guide and optimize the visual exploration of potentially relevant regions of interest in the network. Besides community detection, our workflow includes non-relevant data removal, summarization and timeslicing strategies, and heuristics to define relevant network regions. Finally, through the multiple and complementary visual components provided by the system, users are capable of exploring the network data from different perspectives.",
    "caption": null,
    "description": "A system for visualizing large temporal networks",
    "visible": false,
    "type": "s",
    "papers": []
  },
  {
    "id": 10,
    "title": "TDA applied to network visualization",
    "web_name": "TDANetworkVisualization",
    "figure": "/projects/TDANetworkVisualization.png",
    "abstract": "Networks represent a useful and widely adopted structure to model systems from distinct areas, such as computer science, biology, and others. Visual analysis of temporal networks comprises an effective way to understand the network dynamics. It facilitates the identification of patterns, anomalies, and other network properties, thus resulting in fast decision making. The network temporal resolution plays an important role in the layout construction and, consequently, in the visual analysis. In several scenarios, as, for example, when the network is temporally sparse, changing the temporal resolution through the grouping of edges from subsequent timestamps \u2013 a process called timeslicing \u2013 may facilitate the analysis and highlight patterns that would be difficult to see using the original resolution. Choosing the length of time that each resulting timestamp (or timeslice) must have, however, is not a trivial task. Given that the identification of meaningful patterns depends on the considered length of time, this project aims to create a visualization methodology along with a web-based visual analytic system that will allow users to explore temporal networks at different lengths. The methodology we propose leverages Topological Data Analysis to highlight structural changes that occur in the network for each timeslicing approach. Based on this information, users interact with the proposed system to compare different timeslicing and explore the network.",
    "caption": null,
    "description": "Exploring temporal networks at different timeslice lengths using Topological Data Analysis",
    "visible": false,
    "type": "s",
    "papers": []
  },
  {
    "id": 11,
    "title": "Explainable Artificial Intelligence",
    "web_name": "XAI",
    "figure": "/projects/XAI.png",
    "abstract": "As Artificial Intelligence (AI) systems become more complex, there is a necessity to understand their functioning and decisions. To approach this, Explainable AI (XAI) plays an essential role by developing machine learning models that are inherently explainable or interpretable and, when it is not possible, by developing methods to explain these models in a human-understandable way. Visual systems incorporating explainability methods can assist final users and experts in better analyzing the object of interest when it involves the application of highly complex machine learning models. In this project, we aim to develop XAI methods and frameworks to improve the explainability of AI models. One front is the development of image-based-model explainability methods such as Style Augmentation in image classification. Another front is the improvement of the plausibility of text classification explanations through the incorporation of human annotations. We are also interested in advancing methods of attributing computer vision model decisions to images from its training data. Finally, the existing and these new findings are being applied in visualization workflows to improve the degree to which the final user, usually an expert, comprehends the inner workings of the models and the data being analyzed, with a particular focus on the legal domain.",
    "caption": null,
    "description": "XAI helps to understand, know, and analyze the behavior of complex models",
    "visible": true,
    "type": "c",
    "papers": [39, 40, 36]
  }
]
